{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as ps\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import math\n",
    "\n",
    "# from config import config\n",
    "import data_helpers\n",
    "from data_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ID = 'UK.B.A.14'\n",
    "TRAIN_PERCENT= 90\n",
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 48\n",
    "LEARNING_RATE = 0.00001\n",
    "LOSS_MULTIPLIER = 2.0\n",
    "TEAM_EMBS = 50\n",
    "LOSS_RAMBDA = 0.5\n",
    "NORM_PP_PATIENCY = 100\n",
    "MAE_NOT_MSE_LOSS = True\n",
    "TRANSFORMER_DROP = 0.2\n",
    "TRANSFORMER_LAYERS = 6\n",
    "TRANSFORMER_HEADS = 6\n",
    "# ADAPTORS_LAYERS = 10\n",
    "RESET_HISTORY = False\n",
    "MIN_PROFIT = -0.10\n",
    "DISTRIBUTION_KEYS = [2.0, 1.0, 0.5, 0.0, -0.5, -1.0]\n",
    "MIN_PROFIT_P_PER_GAME_PER_QGROUP = 0.5\n",
    "id_to_ids_filename = 'England-200-1e-07-7300-75-0.8-False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDirPath = \"./data/football-data-co-uk/England\"\n",
    "df = data_helpers.get_master_df_from_football_data_co_uk(countryDirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "['tottenham', 'arsenal', 'liverpool', '[UNK]', 'tottenham', 'chelsea', '[UNK]', 'man_united', '[UNK]', '[UNK]', '[UNK]']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 4, 58, 0, 101, 27, 0, 62, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tottenham arsenal liverpool tottenham chelsea man_united'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_team = creat_team_tokenizer_uk(df)\n",
    "print(tokenizer_team.get_vocab_size())\n",
    "\n",
    "teams = ['Tottenham', 'Arsenal', 'Liverpool', 'what?', 'Tottenham', 'Chelsea', 'e_t', 'Man United', '1234', '[HOME]', '[AWAY]']\n",
    "teams = [team.strip() for team in [re.sub(r\"\\s\", \"_\", item) for item in teams]]\n",
    "teams = \" \".join(teams)\n",
    "encoding = tokenizer_team.encode(teams)\n",
    "# encoding = tokenizer.encode(\"\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.type_ids)\n",
    "print(encoding.ids)\n",
    "\n",
    "tokenizer_team.decode(encoding.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyperparams:    \n",
    "    nDivisions = 4 + 1  # E0, E1, E2, E3, and Unknown\n",
    "    division_embs = 4\n",
    "    nTeams = tokenizer_team.get_vocab_size()    # including Unknown\n",
    "    team_embs = TEAM_EMBS\n",
    "    nGoals  = 10  # 0 for 0 goals not for Unknown.\n",
    "    goal_embs = 4\n",
    "    nResults = 4    # HWin, Draw, AWin, and Unknown\n",
    "    result_embs = 4\n",
    "    # Mate d_model an even number!!!\n",
    "    d_model = get_std_size()    + division_embs * len(Div_cols) + team_embs * len(Team_cols) \\\n",
    "                                + goal_embs * len(Goal_cols) + result_embs * len(Result_cols)\n",
    "    batch_size = BATCH_SIZE\n",
    "    days_spanning_years = 30\n",
    "    num_layers = TRANSFORMER_LAYERS\n",
    "    num_heads = TRANSFORMER_HEADS\n",
    "    m365_size = 1\n",
    "    initial_m365 = 0.9\n",
    "    # d_model = team_emb_size * 2 + country_emb_size * 3 + odds_size + outcome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(os.getcwd(), 'data', 'id_to_ids', id_to_ids_filename + '.json')\n",
    "id_to_ids = data_helpers.LoadJsonData(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(ids) for (tag, label, ids) in id_to_ids.values()]\n",
    "maxLen = max(lengths)\n",
    "plt.hist(lengths, np.linspace(0, int(maxLen*1.1), int(maxLen*1.1) + 1))\n",
    "plt.ylim(plt.ylim())\n",
    "maxLen = max(lengths)\n",
    "# plt.plot([maxLen, maxLen], plt.ylim())\n",
    "plt.title(f'Max length of ids: {maxLen}')\n",
    "\n",
    "MAX_TOKENS = maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100000, 'E0', datetime.date(2004, 1, 11), 'Man_City', 'Norwich', 1.72, 3.4, 5.0, 1.7, 3.2, 5.0, 1.65, 3.3, 4.4, 1.66, 3.1, 5.0, 1.0, 0.0, 1, 1, 'H', 'D', 19.0, 10.0, 11.0, 5.0, 9.0, 4.0, 10.0, 13.0, 1.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "id_cols = ['id']\n",
    "Div_cols = ['Div']\n",
    "Date_cols = ['Date']\n",
    "Team_cols = ['HomeTeam', 'AwayTeam']\n",
    "Odds_cols = ['B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA']\n",
    "BB_cols = id_cols + Div_cols + Date_cols + Team_cols + Odds_cols\n",
    "\n",
    "Half_Goal_cols = ['HTHG', 'HTAG']\n",
    "Full_Goal_cols = ['FTHG', 'FTAG']\n",
    "Goal_cols = Half_Goal_cols + Full_Goal_cols\n",
    "Result_cols = ['HTR', 'FTR']    # A function of Goal_cols, but contribute to better representation.\n",
    "Shoot_cols = ['HS', 'AS']\n",
    "ShootT_cols = ['HST', 'AST']\n",
    "Corner_cols = ['HC', 'AC']\n",
    "Faul_cols = ['HF', 'AF']\n",
    "Yellow_cols = ['HY', 'AY']    # H/A Yellow Cards, H/A Red Cards\n",
    "Red_cols = ['HR', 'AR']    # H/A Yellow Cards, H/A Red Cards\n",
    "AB_cols = Goal_cols + Result_cols + Shoot_cols + ShootT_cols + Corner_cols + Faul_cols + Yellow_cols + Red_cols\n",
    "\n",
    "# underscore_prefixed lists have discontinued columns.\n",
    "BBAB_cols = BB_cols + AB_cols\n",
    "_Cols_List_to_Embedd = [Div_cols, Team_cols, Goal_cols, Result_cols]\n",
    "_Cols_List_to_Standardize = [Odds_cols, Shoot_cols, ShootT_cols, Corner_cols, Faul_cols, Yellow_cols, Red_cols]\n",
    "_Cols_List_for_Label = [Full_Goal_cols, Odds_cols]\n",
    "_Label_cols = Full_Goal_cols + Odds_cols\n",
    "\n",
    "BBAB_cols = BB_cols + AB_cols\n",
    "base_bbab = list(df.loc[df['id'] == 100000, BBAB_cols].iloc[0, :])\n",
    "print(base_bbab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B365H': (3.1630270400481795, 1.4687447460469159, 46.0), 'HS': (11.39694154084398, 4.709404811489129, 43.0), 'HST': (4.815343915343916, 2.759941394538306, 24.0), 'HC': (5.34632855852368, 2.842282967456132, 24.0), 'HF': (11.421925409730287, 3.7612036770331043, 77.0), 'HY': (1.5455413601755066, 1.2348960213340971, 11.0), 'HR': (0.08013937282229965, 0.2855927650445304, 3.0)}\n"
     ]
    }
   ],
   "source": [
    "std_path = os.path.join('./data', 'datasets', id_to_ids_filename + \".json\")\n",
    "std_params = get_standardization_params(df)\n",
    "print(std_params)\n",
    "data_helpers.SaveJsonData(std_params, std_path)\n",
    "std_params = data_helpers.LoadJsonData(std_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38745"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path = os.path.join('./data', 'datasets', id_to_ids_filename)\n",
    "\n",
    "# ds = generate_dataset_uk(df, id_to_ids, tokenizer_team, std_params)\n",
    "# tf.data.Dataset.save(ds, ds_path)\n",
    "\n",
    "ds = tf.data.Dataset.load(ds_path)\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34870 3875 38745 0\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(ds)\n",
    "train_size = int(TRAIN_PERCENT/100 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_ds = ds.take(train_size)\n",
    "test_ds = ds.skip(train_size)\n",
    "\n",
    "print(len(train_ds), len(test_ds), len(ds), len(ds)-len(train_ds)-len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bbas_tensor = get_dummy_bbas_tensor_uk(df, tokenizer_team, std_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_row(baseId, sequence, base_bb, base_label):\n",
    "    try:\n",
    "        seq_len_org = sequence.shape[0]\n",
    "        nMissings = MAX_TOKENS - seq_len_org\n",
    "        if nMissings > 0:\n",
    "            block = tf.stack([dummy_bbas_tensor] * nMissings, axis=0)\n",
    "            sequence = tf.concat([sequence, block], axis=0) \n",
    "        # print(\"sequence 1\", sequence.shape)\n",
    "        # sequence[:, 2] = base[2] - sequence[:, 2]   # get delta days.\n",
    "        base_bb = base_bb[tf.newaxis, :]    # shape: (seq_len = 1, nFeatures)\n",
    "        mask = tf.Variable([1] * seq_len_org + [0] * nMissings, dtype=tf.int32) ## DO NOT USE tf.constant !!! unstable.\n",
    "        mask = mask[:, tf.newaxis] & mask[tf.newaxis, :]\n",
    "        # print('normalize', sequence.shape, base.shape, mask.shape, mask)\n",
    "        # seq_len_org = tf.Variable(seq_len_org, dtype=tf.int32)    #--------------------------------- comeback\n",
    "        return (baseId, sequence, base_bb, base_label, mask, seq_len_org)\n",
    "    except:\n",
    "        print('normalize_row exception')\n",
    "        print('norm 1', sequence.shape, base_bb.shape, base_label.shape, mask.shape, nMissings)\n",
    "        print('norm 2', baseId, sequence, base_label, mask, nMissings)\n",
    "        # return (baseId, sequence, base_bb, base_label, mask, seq_len_org)\n",
    "\n",
    "def prepare_batch(baseId, sequence, base_bb, base_label, mask, seq_len_org):\n",
    "    # target = tf.one_hot(tf.squeeze(tf.cast(base_bbab[:, :, -1], dtype=tf.int32), axis=-1), hyperparams.target_onehot_size)\n",
    "    return (baseId, sequence, base_bb, mask), (base_label, seq_len_org)     # (X, Y)\n",
    "\n",
    "def normalize_dataset(ds):\n",
    "    return (\n",
    "        ds.map(lambda baseId, sequence, base_bb, base_label: tf.py_function(\n",
    "            func=normalize_row,\n",
    "            inp=[baseId, sequence, base_bb, base_label],\n",
    "            Tout=[tf.int32, tf.float32, tf.float32, tf.float32, tf.int32, tf.int32])) #, tf.data.AUTOTUNE == Instability!!!\n",
    "        )\n",
    "\n",
    "def make_train_batches(ds):\n",
    "    return (\n",
    "        ds\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "        .cache()\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        )\n",
    "\n",
    "def make_test_batches(ds):\n",
    "    return (\n",
    "        ds\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "        .cache()\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_path = os.path.join('./data', 'datasets', id_to_ids_filename + '_train_' + str(TRAIN_PERCENT))\n",
    "if os.path.exists(train_ds_path):\n",
    "    train_ds = tf.data.Dataset.load(train_ds_path)\n",
    "else:\n",
    "    train_ds = normalize_dataset(train_ds)\n",
    "    tf.data.Dataset.save(train_ds, train_ds_path)\n",
    "\n",
    "train_batches = make_train_batches(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_path = os.path.join('./data', 'datasets', id_to_ids_filename + '_test_' + str(TRAIN_PERCENT))\n",
    "if os.path.exists(test_ds_path):\n",
    "    test_ds = tf.data.Dataset.load(test_ds_path)\n",
    "else:\n",
    "    test_ds = normalize_dataset(test_ds)\n",
    "    tf.data.Dataset.save(test_ds, test_ds_path)\n",
    "\n",
    "test_batches = make_test_batches(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(memory, depth):\n",
    "    positions = tf.range(memory.shape[-1], dtype=tf.float32)\n",
    "    fractional_pos = memory * positions    # fractional position: (batch, fractional position #)\n",
    "    depth = depth/2\n",
    "    depths = tf.range(depth, dtype=tf.float32) / depth\n",
    "    depths = tf.pow(10000.0, depths)    # (depth,)\n",
    "    angle_rads = fractional_pos[:, :, tf.newaxis] / depths  # (batch, fractional position #, depth)\n",
    "    # pos_encoding = rearrange([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], 'w b p d -> w h (w t)')\n",
    "    pos_encoding = tf.concat([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], axis=-1)\n",
    "    return pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = tf.ones((100, 200), dtype=tf.float32) * 0.5\n",
    "pos_encoding = positional_encoding(memory, depth=512)\n",
    "# print('pos_encoding', pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0, :, :]\n",
    "# print(pos_encoding.shape)\n",
    "# Plot the dimensions.\n",
    "plt.pcolormesh(pos_encoding.numpy().T, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['id']\n",
    "Div_cols = ['Div']\n",
    "Date_cols = ['Date']\n",
    "Team_cols = ['HomeTeam', 'AwayTeam']\n",
    "Odds_cols = ['B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA']\n",
    "BB_cols = id_cols + Div_cols + Date_cols + Team_cols + Odds_cols\n",
    "\n",
    "Half_Goal_cols = ['HTHG', 'HTAG']\n",
    "Full_Goal_cols = ['FTHG', 'FTAG']\n",
    "Goal_cols = Half_Goal_cols + Full_Goal_cols\n",
    "Result_cols = ['HTR', 'FTR']    # A function of Goal_cols, but contribute to better representation.\n",
    "Shoot_cols = ['HS', 'AS']\n",
    "ShootT_cols = ['HST', 'AST']\n",
    "Corner_cols = ['HC', 'AC']\n",
    "Faul_cols = ['HF', 'AF']\n",
    "Yellow_cols = ['HY', 'AY']    # H/A Yellow Cards, H/A Red Cards\n",
    "Red_cols = ['HR', 'AR']    # H/A Yellow Cards, H/A Red Cards\n",
    "AB_cols = Goal_cols + Result_cols + Shoot_cols + ShootT_cols + Corner_cols + Faul_cols + Yellow_cols + Red_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, hyperparams, isEncoder=True):\n",
    "    super().__init__()\n",
    "    self.isEncoder = isEncoder\n",
    "    self.division_embedding = tf.keras.layers.Embedding(hyperparams.nDivisions, hyperparams.division_embs, dtype=tf.float32, mask_zero=False) # Learn Unknown\n",
    "    self.team_embedding = tf.keras.layers.Embedding(hyperparams.nTeams, hyperparams.team_embs, dtype=tf.float32, mask_zero=False) # Learn Unknown\n",
    "    self.goal_embedding = tf.keras.layers.Embedding(hyperparams.nGoals, hyperparams.goal_embs, dtype=tf.float32, mask_zero=False) # Learn 0-goal\n",
    "    self.result_embedding = tf.keras.layers.Embedding(hyperparams.nResults, hyperparams.result_embs, dtype=tf.float32, mask_zero=False) # Learn Unknown\n",
    "\n",
    "    self.d_model = hyperparams.d_model\n",
    "    # print(self.d_model)\n",
    "    self.position_permuting_dense = tf.keras.layers.Dense(self.d_model)\n",
    "    self.m365_embedding = tf.keras.layers.Embedding(1, hyperparams.m365_size, mask_zero=False, embeddings_initializer = tf.keras.initializers.Ones())\n",
    "\n",
    "    self.idx_Days = BB_cols.index('Date')\n",
    "    assert self.idx_Days == BBAB_cols.index('Date')\n",
    "\n",
    "  def call(self, x):\n",
    "    (sequence, base_bb, mask) = x # sob = sequence or base_bb\n",
    "    sDays = sequence[:, :, self.idx_Days]\n",
    "    bDays = base_bb[:, :, self.idx_Days]\n",
    "    \n",
    "    # BB_cols = id_cols + Div_cols + Date_cols + Team_cols + Odds_cols\n",
    "    # AB_cols = Goal_cols + Result_cols + Shoot_cols + ShootT_cols + Corner_cols + Faul_cols + Yellow_cols + Red_cols\n",
    "\n",
    "    sob = None\n",
    "    if self.isEncoder:\n",
    "      sob = sequence\n",
    "    else:\n",
    "      sob = base_bb\n",
    "\n",
    "    if self.isEncoder:\n",
    "      # Extract odds to remove them\n",
    "      id, div, days, teams, odds, goals, results, remainder \\\n",
    "      = tf.split(sob, [len(id_cols), len(Div_cols), len(Date_cols), len(Team_cols), len(Odds_cols), len(Goal_cols), len(Result_cols),  -1], axis=-1)\n",
    "      # print('1', remainder[0, 0])\n",
    "    else:\n",
    "      # Extract odds to remove them\n",
    "      id, div, days, teams, odds, remainder \\\n",
    "      = tf.split(sob, [len(id_cols), len(Div_cols), len(Date_cols), len(Team_cols), len(Odds_cols), -1], axis=-1)  \n",
    "      # print('2', remainder[0, 0])  \n",
    "\n",
    "    # print('pe 2.7.1 1', div)\n",
    "    div = self.division_embedding(tf.cast(div, dtype=tf.int32))\n",
    "    div = tf.reshape(div, [div.shape[0], div.shape[1], -1])\n",
    "    # print('pe 2.7.1 1', div)\n",
    "    teams = self.team_embedding(tf.cast(teams, dtype=tf.int32))\n",
    "    teams = tf.reshape(teams, [teams.shape[0], teams.shape[1], -1])\n",
    "    if self.isEncoder:\n",
    "      goals = self.goal_embedding(tf.cast(goals, dtype=tf.int32))\n",
    "      goals = tf.clip_by_value(goals, 0, hyperparams.nGoals)\n",
    "      goals = tf.reshape(goals, [goals.shape[0], goals.shape[1], -1])\n",
    "      results = self.result_embedding(tf.cast(results, dtype=tf.int32))\n",
    "      results = tf.reshape(results, [results.shape[0], results.shape[1], -1])\n",
    "    \n",
    "    if self.isEncoder:\n",
    "      concat = [div, teams, goals, results, odds, remainder]\n",
    "    else:\n",
    "      concat = [div, teams, odds, remainder]\n",
    "\n",
    "    sob = tf.concat(concat, axis=-1)\n",
    "    sob = self.position_permuting_dense(sob)\n",
    "\n",
    "    days_ago = tf.cast(bDays - sDays, dtype=tf.float32) if self.isEncoder else tf.cast(bDays - bDays, dtype=tf.float32)\n",
    "    \n",
    "    m365 = self.m365_embedding(tf.zeros_like((hyperparams.m365_size,), dtype=tf.float32)) * hyperparams.initial_m365  # expected shape: (1, hyperparams.remain_365_size)\n",
    "    m365 = tf.squeeze(m365, axis=0)\n",
    "    memory_alpha = tf.math.pow(m365, 1.0/365) # (hyperparams.m365_size,)\n",
    "    memory = tf.math.pow(memory_alpha, days_ago[:, :, tf.newaxis])  # decrease as days_ago increase, if memory <= 1.0 as expected.\n",
    "    memory = tf.reduce_mean(memory, axis=-1)\n",
    "\n",
    "    pe = positional_encoding(memory, depth=sob.shape[-1]) # (batch, d_model)\n",
    "    pe = pe / tf.math.sqrt(tf.cast(sob.shape[-1], tf.float32))\n",
    "    sob = sob + pe\n",
    "\n",
    "    if self.isEncoder:\n",
    "      mask = mask\n",
    "    else:\n",
    "      mask = mask[:, 0:sob.shape[1], :]\n",
    "\n",
    "    return (sob, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 200, 152) (48, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "pos = PositionalEmbedding(hyperparams, isEncoder=True)\n",
    "\n",
    "cnt = 2\n",
    "for z in train_batches:\n",
    "    (baseId, sequence, base_bb, mask), (base_label, seq_len_org) = z\n",
    "    cnt -= 1\n",
    "    if cnt == 0: break\n",
    "# print('baseId', baseId)\n",
    "sample_x = (sequence, base_bb, mask)\n",
    "eSob, eMask = pos.call(sample_x)\n",
    "print(eSob.shape, eMask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 200, 152) (48, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "PE = PositionalEmbedding(hyperparams, isEncoder=True)\n",
    "eSob, eMask = PE(sample_x)\n",
    "print(eSob.shape, eMask.shape )\n",
    "del PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1, 152) (48, 1, 200)\n"
     ]
    }
   ],
   "source": [
    "PE = PositionalEmbedding(hyperparams, isEncoder=False)\n",
    "dSob, dMask = PE(sample_x)\n",
    "print(dSob.shape, dMask.shape )\n",
    "del PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "      super().__init__()\n",
    "      self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "      self.layernorm = tf.keras.layers.LayerNormalization()   # So the default -1 axix is normalized across. No inter-token operatoin.\n",
    "      self.add = tf.keras.layers.Add()\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context, mask):\n",
    "      attn_output, attn_scores = self.mha(\n",
    "          query=x,\n",
    "          key=context,\n",
    "          value=context,\n",
    "          attention_mask=mask,\n",
    "          return_attention_scores=True)\n",
    "    \n",
    "      # Cache the attention scores for plotting later.\n",
    "      self.last_attn_scores = attn_scores\n",
    "      x = self.add([x, attn_output])\n",
    "      x = self.layernorm(x)\n",
    "      return x\n",
    "  \n",
    "class GlobalSelfAttention(BaseAttention): \n",
    "    def call(self, x, mask):\n",
    "      attn_output = self.mha(\n",
    "          query=x,\n",
    "          value=x,\n",
    "          key=x,\n",
    "          attention_mask=mask)    # intentional inter-token operation\n",
    "      x = self.add([x, attn_output])  # token-wise\n",
    "      x = self.layernorm(x)         # normalize across the default -1 axis. No inter-token operatoin.\n",
    "      return x\n",
    "  \n",
    "class CausalSelfAttention(BaseAttention): # mask-agnostic\n",
    "    def call(self, x):\n",
    "      attn_output = self.mha(\n",
    "          query=x,\n",
    "          value=x,\n",
    "          key=x,\n",
    "          use_causal_mask = True)     # look-over mask is generagted and used, in decoder layers\n",
    "      x = self.add([x, attn_output])  # mask-agnostic\n",
    "      x = self.layernorm(x)  # normalize across the default -1 axis. No inter-token operatoin.\n",
    "      return x\n",
    "  \n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "      super().__init__()\n",
    "      self.seq = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),    # across -1 axis\n",
    "        tf.keras.layers.Dense(d_model),    # across -1 axis\n",
    "        tf.keras.layers.Dropout(dropout_rate)    # mask-agnostic\n",
    "      ])\n",
    "      self.add = tf.keras.layers.Add()\n",
    "      self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "      x = self.add([x, self.seq(x)])  # mask-agnostic\n",
    "      x = self.layer_norm(x)  # normalize across the default -1 axis. No inter-token operatoin.\n",
    "      return x\n",
    "  \n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "      super().__init__()\n",
    "\n",
    "      self.self_attention = GlobalSelfAttention(\n",
    "          num_heads=num_heads,\n",
    "          key_dim=d_model,\n",
    "          dropout=dropout_rate)\n",
    "\n",
    "      self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "      # x: (batch, max_tokens, d_model), mask: (batch, max_tokens, max_tokens)\n",
    "      x = self.self_attention(x, mask)\n",
    "      x = self.ffn(x)\n",
    "      return x\n",
    "  \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, hyperparams, dropout_rate=0.1):\n",
    "      super().__init__()\n",
    "\n",
    "      self.d_model = hyperparams.d_model\n",
    "      self.num_layers = hyperparams.num_layers\n",
    "\n",
    "      self.pos_embedding = PositionalEmbedding(hyperparams)\n",
    "\n",
    "      self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "      self.enc_layers = [\n",
    "          EncoderLayer(d_model=hyperparams.d_model,\n",
    "                      num_heads=hyperparams.num_heads,\n",
    "                      dff=hyperparams.d_model * 4,\n",
    "                      dropout_rate=dropout_rate)\n",
    "          for _ in range(hyperparams.num_layers)]\n",
    "\n",
    "    def call(self, x):\n",
    "      # x = (sequence, base_bb, mask)\n",
    "      # x[0]: (batch, max_tokens, bbab.len), x[1]: (batch, 1, bb.len), x[2]: (token, max_tokens, max_tokens)\n",
    "      x, mask = self.pos_embedding(x)  # x: (batch, max_tokens, d_model), mask: (batch, max_tokens, max_tokens)\n",
    "      x = self.dropout(x)\n",
    "      for encoder_layer in self.enc_layers:\n",
    "        x = encoder_layer(x, mask)\n",
    "      return x  # Shape `(batch_size, seq_len, d_model)`.\n",
    "  \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                *,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dff,\n",
    "                dropout_rate=0.1):\n",
    "      super(DecoderLayer, self).__init__()\n",
    "\n",
    "      self.causal_self_attention = CausalSelfAttention(\n",
    "          num_heads=num_heads,\n",
    "          key_dim=d_model,\n",
    "          dropout=dropout_rate)\n",
    "      \n",
    "      self.cross_attention = CrossAttention(\n",
    "          num_heads=num_heads,\n",
    "          key_dim=d_model,\n",
    "          dropout=dropout_rate)\n",
    "\n",
    "      self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x, context, cross_attention_mask):\n",
    "      # x: (batch, 1, d_model), context: (batch, max_tokens, d_mode)\n",
    "      x = self.causal_self_attention(x=x)\n",
    "      x = self.cross_attention(x, context, cross_attention_mask)\n",
    "\n",
    "      # Cache the last attention scores for plotting later\n",
    "      self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "      x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "      return x\n",
    "  \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, hyperparams, dropout_rate=0.1):\n",
    "      super(Decoder, self).__init__()\n",
    "\n",
    "      self.d_model = hyperparams.d_model\n",
    "      self.num_layers = hyperparams.num_layers\n",
    "\n",
    "      self.pos_embedding = PositionalEmbedding(hyperparams, isEncoder=False)\n",
    "\n",
    "      self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "      self.dec_layers = [\n",
    "          DecoderLayer(d_model=hyperparams.d_model, num_heads=hyperparams.num_heads,\n",
    "                      dff=hyperparams.d_model * 4, dropout_rate=dropout_rate)\n",
    "          for _ in range(hyperparams.num_layers)]\n",
    "\n",
    "      self.last_attn_scores = None\n",
    "\n",
    "    def call(self, x, context):\n",
    "      # x = (sequence, base_bb, mask)\n",
    "      # x[0]: (batch, max_tokens, bbab.len), x[1]: (batch, 1, bb.len), x[2]: (token, max_tokens, max_tokens)\n",
    "      # context: (batch, max_tokens, d_model)\n",
    "      # `x` is token-IDs shape (batch, target_seq_len)\n",
    "      x, ca_mask = self.pos_embedding(x)  # x: (batch, 1, d_model), ca_mask: (batch, 1, max_tokens)     \n",
    "      x = self.dropout(x)\n",
    "      for decoder_layer in self.dec_layers:\n",
    "        x  = decoder_layer(x, context, ca_mask)\n",
    "      self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "      return x\n",
    "  \n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, hyperparams, dropout_rate=0.1):\n",
    "      super().__init__()\n",
    "      self.encoder = Encoder(hyperparams, dropout_rate=dropout_rate)\n",
    "      self.decoder = Decoder(hyperparams, dropout_rate=dropout_rate)\n",
    "      self.final_layer = tf.keras.layers.Dense(hyperparams.d_model) #-------------- to modify\n",
    "\n",
    "      self.deadEncOut = None\n",
    "\n",
    "    def call(self, inputs):\n",
    "      # inputs = (sequence, base_bb, mask)\n",
    "      # sequence: (batch, max_token, aabb), base: (batch, 1, bb), mask: (batch, max_token, max_token)\n",
    "\n",
    "      x = self.encoder(inputs)  # (batch, max_tokens, d_model)\n",
    "      x = tf.zeros_like(x)  #------------------------------------------------------- inserted for this test\n",
    "      x = self.decoder(inputs, x)  # (batch, 1, d_model)\n",
    "\n",
    "      logits = self.final_layer(x)  # (batch, 1, d_model)\n",
    "      logits = tf.squeeze(logits, axis=-2)  # (batch, d_model)\n",
    "      return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  4490487   \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  7831087   \n",
      "                                                                 \n",
      " dense_29 (Dense)            multiple                  23256     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,344,830\n",
      "Trainable params: 12,344,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_transformer = Transformer(hyperparams)\n",
    "y = sample_transformer(sample_x)\n",
    "\n",
    "sample_transformer.summary()\n",
    "del sample_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaptor(tf.keras.layers.Layer):\n",
    "  def __init__(self, nLayers, d_output, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    dims = [hyperparams.d_model + round( (d_output - hyperparams.d_model) * (layer+1) / (nLayers) ) for layer in range(nLayers)]\n",
    "    layers = [tf.keras.layers.Dense(dim, activation='relu') for dim in dims]\n",
    "    self.seq = tf.keras.Sequential(layers)\n",
    "  def call(self, x):\n",
    "    x = self.seq(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGroup(tf.keras.Model):\n",
    "  softmax = tf.keras.layers.Softmax(axis=-1)\n",
    "  scalar_product = tf.keras.layers.Dot(axes=(-1, -1))\n",
    "\n",
    "  def __init__(self, bookie, nQueries, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.bookie = bookie\n",
    "    self.nQueries = nQueries\n",
    "    self.bookieBase = Adaptor(7, self.nQueries) # 7777777777777777777777777\n",
    "    self.oh_1 = Adaptor(5, self.nQueries)       # 7777777777777777777777777\n",
    "    return\n",
    "\n",
    "  def call(self, input):\n",
    "    # inputs.shape: (batch, d_model)\n",
    "    base = self.bookieBase(input)        # (batch, nQueries)\n",
    "    stake_p = QGroup.softmax(base)            # (batch, nQueries)\n",
    "    oh_1_p = self.oh_1(base)                  # (batch, nQueries)\n",
    "    return (oh_1_p, stake_p)  # (batch, 3), (batch, nQueries) \n",
    "\n",
    "  #------------------------------- call used in UK.B.A.01 -------------------------  \n",
    "  # def call(self, input):\n",
    "  #   # inputs.shape: (batch, d_model)\n",
    "  #   base = self.bookieBase(input)        # (batch, nQueries)\n",
    "  #   stake_p = QGroup.softmax(base)            # (batch, nQueries)\n",
    "  #   oh_1_p = self.oh_1(base)                  # (batch, nQueries)\n",
    "  #   profit_p = tf.math.multiply(oh_1_p, stake_p)   # (batch, nQueries)\n",
    "  #   return (profit_p, stake_p)  # (batch, nQueries), (batch, nQueries) \n",
    "\n",
    "  #------------------------------- call in UK.B.A.02, this version -----------\n",
    "  # def call(self, input):\n",
    "  #   # inputs.shape: (batch, d_model)\n",
    "  #   base = self.bookieBase(input)             # (batch, nQueries)\n",
    "  #   stake_p = QGroup.softmax(base)            # (batch, nQueries)\n",
    "  #   oh_1_p = self.oh_1(base)                  # (batch, nQueries)\n",
    "  #   profit_p = self.scalar_product([oh_1_p, stake_p]) # (batch, 1)\n",
    "  #   return (profit_p, stake_p)  # (batch, 1), (batch, nQueries) \n",
    "  \n",
    "  #------------------------------- call in UK.B.A.03, a futrue version -----------\n",
    "  # # profit_p is free and independent of stake_p\n",
    "  # def call(self, input):\n",
    "  #   # inputs.shape: (batch, d_model)\n",
    "  #   base = self.bookieBase(input)             # (batch, nQueries)\n",
    "  #   stake_p = QGroup.softmax(base)            # (batch, nQueries)\n",
    "  #   profit_p = self.profit(base)              # (batch, 1)\n",
    "  #   return (profit_p, stake_p)  # (batch, 1), (batch, nQueries) \n",
    "\n",
    "  #----- ToDo: replace self.scalar_product layer with a tf scalar product function, for speed.\n",
    "  def h_true(self, ftGoals):  # Defines this QGroup. This is for 1X2 QGroup. Derived classes re-define this funciton.\n",
    "    # ftGoals:  (batch, 2)\n",
    "    ftGoals = tf.cast(ftGoals, dtype=tf.int32)  # (batch, 2)\n",
    "    h = (tf.math.greater(ftGoals[..., 0], ftGoals[..., 1]), tf.math.equal(ftGoals[..., 0], ftGoals[..., 1]), tf.math.less(ftGoals[..., 0], ftGoals[..., 1]))\n",
    "    h = tf.cast(tf.transpose(h), dtype=tf.float32)  # (batch, nQueries)\n",
    "    return h\n",
    "\n",
    "  def profit_true(self, ftGoals, odds):\n",
    "    stake_t = self.h_true(ftGoals)  # (batch, nQueries)\n",
    "    oh_1_true = tf.math.multiply(odds, self.h_true(ftGoals)) - 1.0  # (batch, nQueries)\n",
    "    profit_t = self.scalar_product([oh_1_true, stake_t])  # (batch, 1)\n",
    "    return profit_t\n",
    "\n",
    "  #-------------------- THis loss is NOT used in action versions.\n",
    "  def loss(self, profit_p, stake_p, ftGoals, odds, rambda):\n",
    "    # profit_p: (batch, 1)\n",
    "    # stake_p:  (batch, nQueries)\n",
    "    # ftGoals:  (batch, 2)\n",
    "    # odds:     (batch, nQueries)\n",
    "    # rambda:   ()\n",
    "    profit_t = self.profit_true(ftGoals, odds)  # (batch, 1)\n",
    "    if MAE_NOT_MSE_LOSS:\n",
    "        profit_p_err = tf.reduce_mean(tf.math.abs(profit_t - profit_p), axis=None) # (), profit dimention.\n",
    "    else:\n",
    "        profit_p_err = tf.reduce_mean(tf.math.pow(profit_t - profit_p, 2.0), axis=None) # (), profit dimention.\n",
    "\n",
    "    oh_1_t = tf.math.multiply(odds, self.h_true(ftGoals)) - 1.0   # (batch, nQueries)\n",
    "    profit_back = self.scalar_product([oh_1_t, stake_p])    # (batch, 1)\n",
    "    profit_back = tf.reduce_mean(profit_back, axis=None)    # ()\n",
    "    loss = (1.0-rambda) * profit_p_err - profit_back * rambda # ()\n",
    "    return loss # ()\n",
    "  \n",
    "  def oh_1_loss(self, oh_1_p, ftGoals, odds):\n",
    "    # oh_1_p: (bacth, nQueries)\n",
    "    h_true = self.h_true(ftGoals)\n",
    "    oh_1_t = tf.multiply(odds, h_true)  # (batch, nQueries)\n",
    "    if MAE_NOT_MSE_LOSS:\n",
    "        profit_p_err = tf.reduce_mean(tf.math.abs(oh_1_t - oh_1_p), axis=-1) # (batch, ), profit dimention.\n",
    "    else:\n",
    "        profit_p_err = tf.reduce_mean(tf.math.pow(oh_1_t - oh_1_p, 2.0), axis=-1) # (batch, ), profit dimention.\n",
    "    \n",
    "    return profit_p_err # (batch, )\n",
    "\n",
    "  #--------------------------------------- Used as profit_back_with_batch in UK.B.A.01\n",
    "  def profit_eval(self, ftGoals, odds, stake_p):\n",
    "    oh_1_t = tf.math.multiply(odds, self.h_true(ftGoals)) - 1.0\n",
    "    profit_e = QGroup.scalar_product([oh_1_t, stake_p])\n",
    "    return profit_e   # (batch, 1)\n",
    "\n",
    "  #-------------------------------------- The same as 'profit_eval' above --------------\n",
    "  def profit_back_with_batch(self, ftGoals, odds, stake_p):\n",
    "    oh_1_t = tf.math.multiply(odds, self.h_true(ftGoals)) - 1.0\n",
    "    profit_back = self.scalar_product([oh_1_t, stake_p])    # (batch, 1)\n",
    "    return profit_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[3.0, 3.0, 4.0], [0.1, 0.7, 0.3]])\n",
    "one_hot_a = tf.squeeze(tf.one_hot(tf.nn.top_k(a).indices, tf.shape(a)[-1]), axis=1)\n",
    "print(one_hot_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGroup1X2(QGroup):\n",
    "  def __init__(self, bookie, dropout_rate=0.1):\n",
    "    super().__init__(bookie=bookie, nQueries=3, dropout_rate=dropout_rate)\n",
    "    self.qGroupName = '1X2'\n",
    "\n",
    "  def h_true(self, ftGoals):  # Defines this QGroup. This is for 1X2 QGroup.\n",
    "    # ftGoals:  (batch, 2)\n",
    "    ftGoals = tf.cast(ftGoals, dtype=tf.int32)  # (batch, 2)\n",
    "    h = (tf.math.greater(ftGoals[..., 0], ftGoals[..., 1]), tf.math.equal(ftGoals[..., 0], ftGoals[..., 1]), tf.math.less(ftGoals[..., 0], ftGoals[..., 1]))\n",
    "    h = tf.cast(tf.transpose(h), dtype=tf.float32)  # (batch, nQueries)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BettingEPL(tf.keras.Model):\n",
    "  def __init__(self, hyperparams, loss_rambda=1.0, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.transformer = Transformer(hyperparams, dropout_rate=dropout_rate)\n",
    "    self.bookies = ['B365', 'Betfair', 'Interwetten', 'William']\n",
    "    self.qGroups = [QGroup1X2(bookie) for bookie in self.bookies]\n",
    "    self.rambda = loss_rambda     #----------------------- Sensitive rambda!!!, Automate optimizing it.\n",
    "    # self.shift_embedding = tf.keras.layers.Embedding(1, hyperparams.m365_size, mask_zero=False, embeddings_initializer = tf.keras.initializers.Ones())\n",
    "    # self.shift = None\n",
    "\n",
    "  def call(self, input):\n",
    "      x = self.transformer(input)\n",
    "      outputs = [qGroup(x) for qGroup in self.qGroups]\n",
    "      # self.shift = tf.squeeze(self.shift_embedding(0))  # squeeze((1, 1)) = ()\n",
    "      return outputs  # [ ( shape: (batch, 1), shape: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "  \n",
    "  def loss(self, y, outputs):   \n",
    "      # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "      # outputs: # [ ( profit_p: (batch, 1), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "      ftGoals, odds = tf.split(y, [2, -1], axis=-1) # (batch, 2), (batch, sum[qGropu.nQueries for qGroup in self.qGroups])\n",
    "      odds_by_qGroup = tf.split(odds, [qQroup.nQueries for qQroup in self.qGroups], axis=-1)  # [ shape: (batch, qGroup.nQueries) for qGroup in self.qGroups ]\n",
    "      losses = [qGroup.loss(profit_p, stake_p, ftGoals, odds, self.rambda) for (qGroup, odds, (profit_p, stake_p)) in zip(self.qGroups, odds_by_qGroup, outputs)]\n",
    "      # losses: [()] * nQGroup\n",
    "      losses = tf.stack(losses, axis=0) # (nQGroups,)\n",
    "      loss_value = tf.math.mean_reduce(losses, axis=None)\n",
    "      return loss_value\n",
    "  \n",
    "  def profit_back_over_qGroups(self, y, outputs):\n",
    "      # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "      # outputs: # [ ( oh_1_p: (batch, nQueries), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "      ftGoals, odds = tf.split(y, [2, -1], axis=-1)\n",
    "      odds_by_qGroup = tf.split(odds, [qQroup.nQueries for qQroup in self.qGroups], axis=-1)\n",
    "      profit_back = [qGroup.profit_back_with_batch(ftGoals, odds, stake_p) for (qGroup, odds, (_, stake_p)) in zip(self.qGroups, odds_by_qGroup, outputs)]\n",
    "      # profit_back = [(batch, 1) for _ in self.qGroups]\n",
    "      profit_back = tf.concat(profit_back, axis=-1) # (batch, nQGroups)\n",
    "      return profit_back  # A function of stake_p and truth.\n",
    "  \n",
    "  #---------------------------------- The same as in UK.B.A.01, with a bit of code factorization.\n",
    "  def action_loss(self, y, outputs, selectivity):\n",
    "      # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "      # outputs: # [ ( oh_1_p: (batch, nQueries), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "      ftGoals, odds = tf.split(y, [2, -1], axis=-1) # (batch, 2), (batch, sum[qGropu.nQueries for qGroup in self.qGroups])\n",
    "      odds_by_qGroup = tf.split(odds, [qQroup.nQueries for qQroup in self.qGroups], axis=-1)  # [ shape: (batch, qGroup.nQueries) for qGroup in self.qGroups ]\n",
    "      oh_1_loss = [qGroup.oh_1_loss(oh_1_p, ftGoals, odds) for (qGroup, odds, (oh_1_p, _)) in zip(self.qGroups, odds_by_qGroup, outputs)] # [(batch,)] * nQGroups\n",
    "      oh_1_loss = tf.stack(oh_1_loss, axis=-1)  # sure (batch, nQGroups)\n",
    "      oh_1_loss = tf.math.reduce_mean(oh_1_loss, axis=None)  # ()\n",
    "      \n",
    "      profit_p = [tf.math.reduce_sum(tf.multiply(oh_1_p, stake_p), axis=-1, keepdims=True) for (oh_1_p, stake_p) in outputs]   # [ shape: (batch, 1) for _ self.qGroups ]\n",
    "      profit_p = tf.concat(profit_p, axis=-1) # (batch, nQGroups)\n",
    "\n",
    "      #======================================================================================================\n",
    "      #   This block simulates the betting action of selecting QGROUP where profit_p is high..\n",
    "      #   Note argmax-based selecting has no gradient.\n",
    "      #======================================================================================================\n",
    "      # least_profit = tf.reduce_min(profit_p, axis=-1)\n",
    "      # delta = tf.reduce_max(profit_p, axis=-1) - least_profit\n",
    "      # normal_profit = tf.transpose(tf.transpose(profit_p) - least_profit)\n",
    "      # normal_profit = tf.transpose(tf.transpose(normal_profit)/(delta + 1e-9)) # no tf.keras.backend.epsilon\n",
    "      # is_zero = ((1.0 - tf.reduce_max(normal_profit, axis=1)))\n",
    "      # normal_profit = tf.transpose(tf.transpose(normal_profit) + is_zero) # (batch, nQGroups). A function of profit_p     \n",
    "      # normal_profit = normal_profit * selectivity + 1.0  # self.shift\n",
    "      \n",
    "      #======================================================================================================\n",
    "      #   This block simulates the betting action of selecting games and qGroups where profit_p is high..\n",
    "      #   Note argmax-based selecting has no gradient.\n",
    "      #======================================================================================================\n",
    "      profit_read = tf.identity(profit_p)\n",
    "      min = tf.reduce_min(profit_read); max = tf.reduce_max(profit_read)\n",
    "      normal_profit = (profit_read - min) / (max-min + 1e-12) * selectivity # (batch,)   [0, 1]\n",
    "      normal_profit = normal_profit + 1.0\n",
    "\n",
    "      profit_back = self.profit_back_over_qGroups(y, outputs) # (batch, nQGroups) # A function of stake_p and truth.\n",
    "\n",
    "      mul = tf.multiply(normal_profit, profit_back)   # (batch, nQGroups)\n",
    "      mean_profit_per_game = tf.math.reduce_mean(mul, axis=None)  # ()\n",
    "      \n",
    "      return  (- mean_profit_per_game + oh_1_loss)\n",
    "\n",
    "  #---------------------------------- The same as in UK.B.A.01, with a bit of code factorization.\n",
    "  def back_test(self, y, outputs):\n",
    "    # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "    # outputs: # [ ( shape: (batch, 1), shape: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "    profit_back = self.profit_back_over_qGroups(y, outputs) # (batch, nQGroups)\n",
    "\n",
    "    # find the most-profitable QGroup idx\n",
    "    profits_p = [tf.math.reduce_sum(profit_p, axis=-1, keepdims=True) for (profit_p, _) in outputs]   # [ shape: (batch, 1) for _ self.qGroups ]\n",
    "    profits_p = tf.concat(profits_p, axis=-1) # (batch, len(self.qGroups))    \n",
    "    bestQuery = tf.cast(tf.argmax(profits_p, axis=-1), dtype=tf.int32)   # (batch,)\n",
    "    range = tf.range(bestQuery.shape[0], dtype=tf.int32) # (batch,)\n",
    "    best_idx = tf.stack([range, bestQuery], axis=1) # (batch, 2)\n",
    "    \n",
    "    best_profits_eval = tf.gather_nd(profit_back, best_idx)  # (batch, )\n",
    "    profit_eval_mean = tf.math.reduce_mean(best_profits_eval)\n",
    "    return profit_eval_mean\n",
    "  \n",
    "  def back_test_over_chosen_games_and_qGroups(self, y, outputs):\n",
    "    # Choose (game, qGroup), which is greater than 0.05, or MIN_PROFIT_P_PER_GAME_PER_QGROUP\n",
    "    # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "    # outputs: # [ ( oh_1_p: (batch, nQueries), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "    profit_p = [tf.math.multiply(p_p, s_p) for (p_p, s_p) in outputs]  # [ (batch, nQueries) ] * nQGroups\n",
    "    profit_p = [tf.math.reduce_sum(p_p, axis=-1, keepdims=True) for p_p in profit_p] # [(batch, 1)] * nQGroups\n",
    "    profit_p = tf.concat(profit_p, axis=-1)   # (batch, nQGroups))\n",
    "    profit_back = self.profit_back_over_qGroups(y, outputs)   # (batch, nQGroups)\n",
    "\n",
    "    best_idx = tf.where(profit_p > MIN_PROFIT_P_PER_GAME_PER_QGROUP)  # (nBettings, 2). nBettings unknown yet.\n",
    "\n",
    "    nBettings = 0\n",
    "    profit_back_mean_per_betting = MIN_PROFIT\n",
    "    if best_idx.shape[0] > 0:\n",
    "      best_profits_back = tf.gather_nd(profit_back, best_idx)   # (nBettings, )\n",
    "      nBettings = best_profits_back.shape[0]\n",
    "      profit_back_mean_per_betting = tf.math.reduce_mean(best_profits_back)\n",
    "    return profit_back_mean_per_betting, nBettings\n",
    "  \n",
    "  def back_test_over_chosen_games_and_qGroups_for_distribution(self, y, outputs, keys):\n",
    "    # Choose (game, qGroup), which is greater than 0.05, or MIN_PROFIT_P_PER_GAME_PER_QGROUP\n",
    "    # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "    # outputs: # [ ( oh_1_p: (batch, nQueries), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "    profit_p = [tf.math.multiply(p_p, s_p) for (p_p, s_p) in outputs]  # [ (batch, nQueries) ] * nQGroups\n",
    "    profit_p = [tf.math.reduce_sum(p_p, axis=-1, keepdims=True) for p_p in profit_p] # [(batch, 1)] * nQGroups\n",
    "    profit_p = tf.concat(profit_p, axis=-1)   # (batch, nQGroups))\n",
    "    profit_back = self.profit_back_over_qGroups(y, outputs)   # (batch, nQGroups)\n",
    "\n",
    "    profit_back_mean_per_betting_list = []\n",
    "    nBettings_list = []\n",
    "\n",
    "    for key in keys:\n",
    "      best_idx = tf.where(profit_p > key)  # (nBettings, 2). nBettings unknown yet.\n",
    "\n",
    "      nBettings = 0\n",
    "      profit_back_mean_per_betting = MIN_PROFIT\n",
    "      if best_idx.shape[0] > 0:\n",
    "        best_profits_back = tf.gather_nd(profit_back, best_idx)   # (nBettings, )\n",
    "        nBettings = best_profits_back.shape[0]\n",
    "        profit_back_mean_per_betting = tf.math.reduce_mean(best_profits_back)\n",
    "      profit_back_mean_per_betting_list.append(float(profit_back_mean_per_betting))\n",
    "      nBettings_list.append(nBettings)\n",
    "    return profit_back_mean_per_betting_list, nBettings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[3.0, 3.0, 4.0], [0.1, 0.7, 0.3]])\n",
    "one_hot_a = tf.squeeze(tf.one_hot(tf.nn.top_k(a).indices, tf.shape(a)[-1]), axis=1)\n",
    "print(one_hot_a)\n",
    "# one_hot_a = [[ 0.  0.  1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "(48, 3) (48, 3)\n",
      "Model: \"betting_epl\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer_1 (Transformer)  multiple                 12344830  \n",
      "                                                                 \n",
      " q_group1x2 (QGroup1X2)      multiple                  74282     \n",
      "                                                                 \n",
      " q_group1x2_1 (QGroup1X2)    multiple                  74282     \n",
      "                                                                 \n",
      " q_group1x2_2 (QGroup1X2)    multiple                  74282     \n",
      "                                                                 \n",
      " q_group1x2_3 (QGroup1X2)    multiple                  74282     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,641,958\n",
      "Trainable params: 12,641,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPL = BettingEPL(hyperparams, loss_rambda = LOSS_RAMBDA, dropout_rate=TRANSFORMER_DROP)\n",
    "\n",
    "x = (sequence, base_bb, mask)\n",
    "y = EPL(sample_x, training=True)\n",
    "print(len(y))\n",
    "print(len(y[0]))\n",
    "(profit_p, stake_p) = y[0]\n",
    "print(profit_p.shape, stake_p.shape)\n",
    "# print(profit_p, stake_p)   # profit_p tend to have the same sign in the same batch.\n",
    "# shift = tf.squeeze(EPL.layers[-1].get_weights()).numpy()\n",
    "# print('shift', shift)\n",
    "\n",
    "EPL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = CustomSchedule(hyperparams.d_model)\n",
    "\n",
    "learning_rate = LEARNING_RATE\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.95, beta_2=0.95, epsilon=1e-9)\n",
    "# optimizer = tf.keras.optimizers.Adadelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def masked_loss_uk(label, y_pred):\n",
    "  # lable = (target(batch, 3), base_bb(batch, 1, 9), seq_len(batch, 1)), y_pred: (batch, 3)\n",
    "  y_true = label[0]   # one_hot: (batch, 3)\n",
    "  seq_len = label[2]  # (batch, 1)\n",
    "\n",
    "  mask = y_true != 0 \n",
    "  loss = loss_object(y_true, y_pred)\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask) # eq. sum_loss / batch\n",
    "  return loss\n",
    "\n",
    "\n",
    "class recall():\n",
    "  def __init__(self, name='recall', min_seq_len=5, **kwargs):\n",
    "    self.min_seq_len = min_seq_len\n",
    "    self.n = None\n",
    "    self.recall = None\n",
    "    self.reset()\n",
    "\n",
    "  def update_state(self, label, y_pred):\n",
    "    # lable = (target(batch, 3), base_bb(batch, 1, 9), seq_len(batch,)), y_pred: (batch, 3)\n",
    "    y_true = label[0]   # one_hot: (batch, 3)\n",
    "    seq_len = label[2]  # (batch)\n",
    "\n",
    "    seq_len_mask = tf.cast(seq_len >= self.min_seq_len, dtype=tf.float32)[:, tf.newaxis, tf.newaxis]\n",
    "    y_true = y_true * seq_len_mask\n",
    "    y_pred = y_pred * seq_len_mask \n",
    "\n",
    "    # print('recall', y_true.shape, y_pred.shape, seq_len_mask.shape)\n",
    "\n",
    "    true_positives = tf.math.reduce_sum(y_true * y_pred)\n",
    "    # print('recall', true_positives.numpy())\n",
    "    possible_positives = tf.math.reduce_sum(y_true)\n",
    "    recall_keras = true_positives / (possible_positives + 1e-9) #tf.keras.backend.epsilon())\n",
    "    self.n += 1\n",
    "    self.recall = self.recall * (self.n-1)/self.n + recall_keras.numpy() / self.n\n",
    "\n",
    "\n",
    "  def result(self):\n",
    "    return self.recall\n",
    "  \n",
    "  def reset(self):\n",
    "    self.n = 0\n",
    "    self.recall = 0.0\n",
    "  \n",
    "recall_object = recall(min_seq_len=5)\n",
    "\n",
    "class precision():\n",
    "  def __init__(self, name='precision', min_seq_len=5, **kwargs):\n",
    "    self.min_seq_len = min_seq_len\n",
    "    self.n = None\n",
    "    self.precision = None\n",
    "    self.reset()\n",
    "\n",
    "  def update_state(self, label, y_pred):\n",
    "    # lable = (target(batch, 3), base_bb(batch, 1, 9), seq_len(batch,)), y_pred: (batch, 3)\n",
    "    y_true = label[0]   # one_hot: (batch, 3)\n",
    "    seq_len = label[2]  # (batch, 1)\n",
    "\n",
    "    seq_len_mask = tf.cast(seq_len >= self.min_seq_len, dtype=tf.float32)[:, tf.newaxis, tf.newaxis]\n",
    "    y_true = y_true * seq_len_mask\n",
    "    y_pred = y_pred * seq_len_mask \n",
    "\n",
    "    true_positives = tf.math.reduce_sum(y_true * y_pred)\n",
    "    predicted_positives = tf.math.reduce_sum(y_pred)\n",
    "    precision_keras = true_positives / (predicted_positives + 1e-9) #tf.keras.backend.epsilon())\n",
    "    self.n += 1\n",
    "    self.precision = self.precision * (self.n-1)/self.n + precision_keras.numpy() / self.n\n",
    "\n",
    "  def result(self):\n",
    "    return self.precision\n",
    "  \n",
    "  def reset(self):\n",
    "    self.n = 0\n",
    "    self.precision = 0.0\n",
    "\n",
    "precision_object = precision(min_seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y, selectivity):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = EPL(x, training=True)  # [ (batch, 1), (batch, nQueries) for _ in bookies]\n",
    "        loss_value = EPL.action_loss(y, outputs, selectivity)\n",
    "    \n",
    "    grads = tape.gradient(loss_value, EPL.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, EPL.trainable_weights))\n",
    "    # recall_object.update_state(y, logits)\n",
    "    # precision_object.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x, y, selectivity):\n",
    "    outputs = EPL(x, training=False)  # [ (batch, 1), (batch, nQueries) for _ in bookies]\n",
    "    loss_value = EPL.action_loss(y, outputs, selectivity)\n",
    "    # recall_object.update_state(y, val_logits)\n",
    "    # precision_object.update_state(y, val_logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function  # gives a wrong result of tf.where(profit_p > MIN_PROFIT_P_PER_GAME_PER_QGROUP)\n",
    "def back_test_step(x, y):\n",
    "    outputs = EPL(x, training=False)  # [ (batch, 1), (batch, nQueries) for _ in bookies]\n",
    "    profit_back_mean_per_betting, nBettings = EPL.back_test_over_chosen_games_and_qGroups(y, outputs)\n",
    "    return profit_back_mean_per_betting, nBettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function  #-------------------- Wierd: no work.\n",
    "def back_test_with_dataset(datsset):\n",
    "    profit_back_mean = 0.0\n",
    "    nBettingsTotal = 0\n",
    "    for step, ((baseId, sequence, base_bb, mask), (base_label, seq_len_org)) in enumerate(datsset):\n",
    "        x = (sequence, base_bb, mask); y = base_label\n",
    "        profit_back_mean_per_betting, nBettings = back_test_step(x, y)\n",
    "        # print('back_test_with_dataset', profit_back_mean_per_betting, nBettings)\n",
    "        if nBettings > 0:\n",
    "            profit_back_mean = (profit_back_mean * nBettingsTotal + profit_back_mean_per_betting * nBettings) / (nBettingsTotal + nBettings)\n",
    "            nBettingsTotal = nBettingsTotal + nBettings\n",
    "    return profit_back_mean, nBettingsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function  #-------------------- Wierd: no work.\n",
    "def test_with_dataset(datsset, selectivity):\n",
    "    n = 0\n",
    "    val_loss = tf.Variable(0.0, dtype=tf.float32)\n",
    "    for step, ((baseId, sequence, base_bb, mask), (base_label, seq_len_org)) in enumerate(datsset):\n",
    "        x = (sequence, base_bb, mask); y = base_label\n",
    "        n += 1\n",
    "        val_loss = val_loss * (n-1) / n + test_step(x, y, selectivity) / n   ###\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class history_class():\n",
    "    def round_sig(self, x, sig=2):\n",
    "            return x\n",
    "            # return round(x, sig-int(math.floor(math.log10(abs(x))))-1)    # domain error for VERY small numbers.\n",
    "    def __init__(self):\n",
    "        self.history = {'loss': [], 'val_loss': [], 'back100': [], 'nBettings': []}\n",
    "    def save(self, path):\n",
    "        data_helpers.SaveJsonData(self.history, path)\n",
    "    def load(self, path):\n",
    "        self.history = data_helpers.LoadJsonData(path)\n",
    "        if self.history is None:\n",
    "            self.history = {'loss': [], 'val_loss': [], 'back100': [], 'nBettings': []}\n",
    "    def to_back100(self, back):\n",
    "        return float(back if back >= 0 else back)\n",
    "    def append(self, loss, val_loss, back, nBettings):\n",
    "        self.history['loss'].append(self.round_sig(float(loss), 4))\n",
    "        self.history['val_loss'].append(self.round_sig(float(val_loss), 4))\n",
    "        self.history['back100'].append(self.round_sig(self.to_back100(back), 4))\n",
    "        self.history['nBettings'].append(int(nBettings))\n",
    "    def len(self):\n",
    "        assert len(self.history['loss']) == len(self.history['val_loss'])\n",
    "        assert len(self.history['loss']) == len(self.history['back100'])\n",
    "        assert len(self.history['loss']) == len(self.history['nBettings'])\n",
    "        return len(self.history['loss'])\n",
    "    def get_latest_item(self):\n",
    "        return (self.history['loss'][-1], self.history['val_loss'][-1], self.history['back100'][-1], self.history['nBettings'][-1])\n",
    "    def get_max_back(self):\n",
    "        return float('-inf') if self.len() <= 0 else max(self.history['back100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_steps(epoch, step, loss, samples_seen):\n",
    "    # recall = recall_object.result()\n",
    "    # precision = precision_object.result()\n",
    "    # print(\"epoch: {}, step: {}, loss: {}, recall: {}, precision: {}, samples_seen: {}\".\n",
    "    #       format(epoch, step, float(loss_value), recall, precision, (step + 1) * hyperparams.batch_size))\n",
    "    print(\"epoch: {}, step: {}, loss: {}, samples_seen: {}          \".\n",
    "            format(epoch, step, float(loss), samples_seen), end='\\r')\n",
    "    # recall_object.reset()\n",
    "    # precision_object.reset()\n",
    "\n",
    "def show_history(history, baseline=0):\n",
    "    plt.figure(figsize=(15,6))\n",
    "\n",
    "    loss = history.history['loss'][baseline:]\n",
    "    val_loss = history.history['val_loss'][baseline:]\n",
    "    losses = loss + val_loss\n",
    "    back = [b100 * 100 for b100 in history.history['back100']][baseline:]\n",
    "    nBettings = history.history['nBettings'][baseline:]\n",
    "    minBack = min(back) if history.len() > 0 else 0.0; maxBack = max(back) if history.len() > 0 else 1.0\n",
    "    minLosses = min(losses) if history.len() > 0 else 0.0; maxLosses = max(losses) if history.len() > 0 else 1.0\n",
    "    loss = [(elem - minLosses) / (maxLosses-minLosses+1e-9) * (maxBack-minBack) + minBack for elem in loss]\n",
    "    val_loss = [(elem - minLosses) / (maxLosses-minLosses+1e-9) * (maxBack-minBack) + minBack for elem in val_loss]\n",
    "    minBettings = min(nBettings) if history.len() > 0 else 0.0; maxBettings = max(nBettings) if history.len() > 0 else 1.0\n",
    "    nBettings = [(elem - minBettings) / (maxBettings-minBettings+1e-9) * (maxBack-minBack) + minBack for elem in nBettings]\n",
    "    base = 0.0\n",
    "\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.plot(back)\n",
    "    plt.plot(nBettings, color='y', linewidth=0.5)\n",
    "    \n",
    "    bestBack = max(back) if history.len() - baseline > 0 else -1.0\n",
    "    bestBackIdx = back.index(bestBack) if back.count(bestBack) > 0 else 0\n",
    "\n",
    "    all = loss + val_loss + back + nBettings\n",
    "    if len(all) > 0:\n",
    "        ymin = min(all); ymax = max(all); xmin = 0; xmax = history.len() - baseline\n",
    "    else:\n",
    "        ymin = 0.0; ymax = 1.0; xmin = 0.0; xmax = 1.0\n",
    "     \n",
    "    plt.axvline(x=bestBackIdx, ymin=ymin, ymax=ymax, color='r', linewidth=0.3)\n",
    "    plt.axhline(y=bestBack, xmin=xmin, xmax=xmax, color='r', linewidth=0.3)\n",
    "    plt.axhline(y=base, color='b', linestyle='-', linewidth=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.title(TEST_ID + \": Avg profit (%) per betting. max: {}, history len: {}\".format(bestBack, history.len()))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'val_loss', '100 * val_profit', 'nBettings'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointPath = os.path.join('./data', 'checkpoints', TEST_ID + '_weights')\n",
    "checkpointPathBest = os.path.join('./data', 'checkpoints', TEST_ID + '_weights_best')\n",
    "historyPath = os.path.join('./data', 'checkpoints', TEST_ID + '_history.json')\n",
    "\n",
    "history = history_class()\n",
    "\n",
    "if RESET_HISTORY:\n",
    "    files = glob.glob(checkpointPath + \"*\")         # \"*.*\" doesn't work\n",
    "    result = [os.remove(file) for file in files]\n",
    "    files = glob.glob(historyPath + \"*\")            # \"*.*\" doens't work\n",
    "    result = [os.remove(file) for file in files]\n",
    "    EPL.save_weights(checkpointPath)    #\n",
    "    history.save(historyPath)\n",
    "\n",
    "try:\n",
    "    EPL.load_weights(checkpointPath)\n",
    "except:\n",
    "    print('Failed to load model weights.')\n",
    "\n",
    "history.load(historyPath)\n",
    "# if history.len() <= 0:\n",
    "#     print('Creating historic baseline...', end='')\n",
    "#     loss = test_with_dataset(train_batches)\n",
    "#     val_loss = test_with_dataset(test_batches)\n",
    "#     back = back_test_with_dataset(test_batches)\n",
    "#     history.append(loss, val_loss, back)\n",
    "#     history.save(historyPath)\n",
    "#     print('done')\n",
    "\n",
    "def save_checkpoint(loss, val_loss, back, nBettings):\n",
    "    EPL.save_weights(checkpointPath)\n",
    "    max_back = history.get_max_back()\n",
    "    if float(history.to_back100(back)) > max_back:\n",
    "        EPL.save_weights(checkpointPathBest)\n",
    "    history.append(loss, val_loss, back, nBettings)\n",
    "    history.save(historyPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7550402879714966, 1.7471927404403687, 1.7456884384155273, 1.7445592880249023, 1.7435890436172485, 1.7433022260665894]\n",
      "[1.749026894569397, 1.743438720703125, 1.742203712463379, 1.7409332990646362, 1.7406765222549438, 1.7407115697860718]\n",
      "[-0.1128406897187233, -0.09834714978933334, -0.11393613368272781, -0.07871612161397934, -0.07725144177675247, -0.07400286942720413]\n",
      "[1350, 1161, 1326, 1474, 1521, 1535]\n"
     ]
    }
   ],
   "source": [
    "for key, value in history.history.items():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history, baseline=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch):\n",
    "    selectivity = 1.0 / NORM_PP_PATIENCY * epoch    # start from 0.05, grow linearly over epoch, and hit 5.0 when epoch == NORM_PP_PATIENCY, which should be about 100.\n",
    "    return selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_25/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_26/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_27/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_28/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/kernel:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/bias:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_29/embeddings:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/beta:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/beta:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/beta:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/beta:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/beta:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'dense_42/kernel:0', 'dense_42/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_25/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_26/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_27/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_28/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/kernel:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/bias:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_29/embeddings:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/beta:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/beta:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/beta:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/beta:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/beta:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'dense_42/kernel:0', 'dense_42/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_25/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_26/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_27/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_28/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/kernel:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/bias:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_29/embeddings:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/beta:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/beta:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/beta:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/beta:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/beta:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'dense_42/kernel:0', 'dense_42/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "epoch: 6, loss: 1.743328332901001, val_loss: 1.7408896684646606, back_test: -0.07556932419538498, nBettings: 1535, baseId_1: 132286, memory365: 0.9000,  time taken: 79s          \n",
      "WARNING:tensorflow:Gradients do not exist for variables ['betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_25/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_26/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_27/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_28/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/kernel:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/bias:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_29/embeddings:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/beta:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/beta:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/beta:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/beta:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/beta:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'dense_42/kernel:0', 'dense_42/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_25/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_26/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_27/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_28/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/kernel:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/bias:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_29/embeddings:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/beta:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/beta:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/beta:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/beta:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/beta:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'dense_42/kernel:0', 'dense_42/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "epoch: 7, loss: 1.7428176403045654, val_loss: 1.7399473190307617, back_test: -0.07509464770555496, nBettings: 1633, baseId_1: 108888, memory365: 0.9000,  time taken: 71s          \n",
      "WARNING:tensorflow:Gradients do not exist for variables ['betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_25/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_26/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_27/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_28/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/kernel:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/bias:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_29/embeddings:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/beta:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/beta:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/beta:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/beta:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/beta:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'dense_42/kernel:0', 'dense_42/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_25/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_26/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_27/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_28/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/kernel:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/bias:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_29/embeddings:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/beta:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/beta:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/beta:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/beta:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/beta:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'dense_42/kernel:0', 'dense_42/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "epoch: 8, loss: 1.7428510189056396, val_loss: 1.7403390407562256, back_test: -0.0791357159614563, nBettings: 1631, baseId_1: 112323, memory365: 0.9000,  time taken: 77s          \n",
      "WARNING:tensorflow:Gradients do not exist for variables ['betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_25/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_26/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_27/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_28/embeddings:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/kernel:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/dense_30/bias:0', 'betting_epl/transformer_1/encoder_1/positional_embedding_5/embedding_29/embeddings:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/multi_head_attention_18/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/global_self_attention_6/layer_normalization_30/beta:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_6/feed_forward_12/layer_normalization_31/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/multi_head_attention_19/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/global_self_attention_7/layer_normalization_32/beta:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_7/feed_forward_13/layer_normalization_33/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/multi_head_attention_20/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/global_self_attention_8/layer_normalization_34/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_8/feed_forward_14/layer_normalization_35/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/multi_head_attention_21/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/global_self_attention_9/layer_normalization_36/beta:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_9/feed_forward_15/layer_normalization_37/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/multi_head_attention_22/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/global_self_attention_10/layer_normalization_38/beta:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'dense_40/kernel:0', 'dense_40/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_10/feed_forward_16/layer_normalization_39/beta:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/query/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/key/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/value/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/kernel:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/multi_head_attention_23/attention_output/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/global_self_attention_11/layer_normalization_40/beta:0', 'dense_41/kernel:0', 'dense_41/bias:0', 'dense_42/kernel:0', 'dense_42/bias:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/gamma:0', 'betting_epl/transformer_1/encoder_1/encoder_layer_11/feed_forward_17/layer_normalization_41/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "epoch: 9, step: 350, loss: 1.748313546180725, samples_seen: 16848           \r"
     ]
    }
   ],
   "source": [
    "epochs = 500;  prev_loss = float(\"inf\")\n",
    "for epoch in range(history.len(), epochs):\n",
    "    start_time = time.time()\n",
    "    m = 0; epoch_loss = 0.0\n",
    "    n = 0; loss = tf.Variable(0.0, dtype=tf.float32); samples_seen = 0\n",
    "    selectivity = schedule(epoch)    # noralized_profit_pred_multiplier is scheduled here.\n",
    "\n",
    "    baseId_1 = None\n",
    "    train_batches = make_train_batches(train_ds)\n",
    "    for step, ((baseId, sequence, base_bb, mask), (base_label, seq_len_org)) in enumerate(train_batches):\n",
    "        if baseId_1 is None: baseId_1 = baseId[0]\n",
    "        # print('train', sequence.shape)\n",
    "        x = (sequence, base_bb, mask); y = base_label\n",
    "        batch_loss = train_step(x, y, selectivity)\n",
    "        n += 1; loss = loss * (n-1) / n + batch_loss / n\n",
    "        m += 1; epoch_loss = epoch_loss * (m-1)/m + batch_loss / m\n",
    "\n",
    "        samples_seen += sequence.shape[0]\n",
    "        if step % 50 == 0:\n",
    "            show_steps(epoch, step, loss, samples_seen)\n",
    "            n = 0; loss = 0.0\n",
    "\n",
    "    show_steps(epoch, step, loss, samples_seen)\n",
    "    val_loss = test_with_dataset(test_batches, selectivity)\n",
    "    profit_back_mean, nBettingsTotal = back_test_with_dataset(test_batches)\n",
    "    # back2 = back_test_with_dataset2(test_batches)\n",
    "    save_checkpoint(epoch_loss, val_loss, profit_back_mean, nBettingsTotal)     #------------------------------------------- comeback\n",
    "\n",
    "    eM365W = EPL.layers[0].layers[0].get_weights()[6]; eM365W = list(tf.reshape(eM365W, (-1,)).numpy())\n",
    "    # shift = tf.squeeze(EPL.layers[-1].get_weights()).numpy()\n",
    "    # dM365W =EPL.layers[0].layers[1].get_weights()[4]; dM365W = list(tf.reshape(dM365W, (-1,)).numpy())\n",
    "\n",
    "    print(\"epoch: {}, loss: {}, val_loss: {}, back_test: {}, nBettings: {}, baseId_1: {}, memory365: {:.4f},  time taken: {:.0f}s          \"\n",
    "          .format(epoch, float(epoch_loss), float(val_loss), float(profit_back_mean), nBettingsTotal, baseId_1, eM365W[0] * hyperparams.initial_m365, (time.time() - start_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
