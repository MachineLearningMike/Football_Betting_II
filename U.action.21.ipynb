{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as ps\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import math\n",
    "\n",
    "# from config import config\n",
    "import data_helpers\n",
    "from data_generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_ID = 'UK.B.A.21'\n",
    "TRAIN_PERCENT= 90\n",
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 48\n",
    "LEARNING_RATE = 0.00001\n",
    "LOSS_MULTIPLIER = 2.0\n",
    "TEAM_EMBS = 50\n",
    "LOSS_RAMBDA = 0.5\n",
    "NORM_PP_PATIENCY = 100\n",
    "MAE_NOT_MSE_LOSS = True\n",
    "TRANSFORMER_DROP = 0.2\n",
    "TRANSFORMER_LAYERS = 6\n",
    "TRANSFORMER_HEADS = 6\n",
    "# ADAPTORS_LAYERS = 10\n",
    "RESET_HISTORY = False\n",
    "MIN_PROFIT = -0.10\n",
    "DISTRIBUTION_KEYS = [2.0, 1.0, 0.5, 0.0, -0.5, -1.0]\n",
    "MIN_PROFIT_P_PER_GAME_PER_QGROUP = -0.1     # -0.5: [0:6], -0.1: [6:  ]\n",
    "id_to_ids_filename = 'England-200-1e-07-7300-75-0.8-False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryDirPath = \"./data/football-data-co-uk/England\"\n",
    "df = data_helpers.get_master_df_from_football_data_co_uk(countryDirPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "['tottenham', 'arsenal', 'liverpool', '[UNK]', 'tottenham', 'chelsea', '[UNK]', 'man_united', '[UNK]', '[UNK]', '[UNK]']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[101, 4, 58, 0, 101, 27, 0, 62, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tottenham arsenal liverpool tottenham chelsea man_united'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_team = creat_team_tokenizer_uk(df)\n",
    "print(tokenizer_team.get_vocab_size())\n",
    "\n",
    "teams = ['Tottenham', 'Arsenal', 'Liverpool', 'what?', 'Tottenham', 'Chelsea', 'e_t', 'Man United', '1234', '[HOME]', '[AWAY]']\n",
    "teams = [team.strip() for team in [re.sub(r\"\\s\", \"_\", item) for item in teams]]\n",
    "teams = \" \".join(teams)\n",
    "encoding = tokenizer_team.encode(teams)\n",
    "# encoding = tokenizer.encode(\"\")\n",
    "print(encoding.tokens)\n",
    "print(encoding.type_ids)\n",
    "print(encoding.ids)\n",
    "\n",
    "tokenizer_team.decode(encoding.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hyperparams:    \n",
    "    nDivisions = 4 + 1  # E0, E1, E2, E3, and Unknown\n",
    "    division_embs = 4\n",
    "    nTeams = tokenizer_team.get_vocab_size()    # including Unknown\n",
    "    team_embs = TEAM_EMBS\n",
    "    nGoals  = 10  # 0 for 0 goals not for Unknown.\n",
    "    goal_embs = 4\n",
    "    nResults = 4    # HWin, Draw, AWin, and Unknown\n",
    "    result_embs = 4\n",
    "    # Mate d_model an even number!!!\n",
    "    d_model = get_std_size()    + division_embs * len(Div_cols) + team_embs * len(Team_cols) \\\n",
    "                                + goal_embs * len(Goal_cols) + result_embs * len(Result_cols)\n",
    "    batch_size = BATCH_SIZE\n",
    "    days_spanning_years = 30\n",
    "    num_layers = TRANSFORMER_LAYERS\n",
    "    num_heads = TRANSFORMER_HEADS\n",
    "    m365_size = 1\n",
    "    initial_m365 = 0.9\n",
    "    # d_model = team_emb_size * 2 + country_emb_size * 3 + odds_size + outcome_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(os.getcwd(), 'data', 'id_to_ids', id_to_ids_filename + '.json')\n",
    "id_to_ids = data_helpers.LoadJsonData(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(ids) for (tag, label, ids) in id_to_ids.values()]\n",
    "maxLen = max(lengths)\n",
    "plt.hist(lengths, np.linspace(0, int(maxLen*1.1), int(maxLen*1.1) + 1))\n",
    "plt.ylim(plt.ylim())\n",
    "maxLen = max(lengths)\n",
    "# plt.plot([maxLen, maxLen], plt.ylim())\n",
    "plt.title(f'Max length of ids: {maxLen}')\n",
    "\n",
    "MAX_TOKENS = maxLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100000, 'E0', datetime.date(2004, 1, 11), 'Man_City', 'Norwich', 1.72, 3.4, 5.0, 1.7, 3.2, 5.0, 1.65, 3.3, 4.4, 1.66, 3.1, 5.0, 1.0, 0.0, 1, 1, 'H', 'D', 19.0, 10.0, 11.0, 5.0, 9.0, 4.0, 10.0, 13.0, 1.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "id_cols = ['id']\n",
    "Div_cols = ['Div']\n",
    "Date_cols = ['Date']\n",
    "Team_cols = ['HomeTeam', 'AwayTeam']\n",
    "Odds_cols = ['B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA']\n",
    "BB_cols = id_cols + Div_cols + Date_cols + Team_cols + Odds_cols\n",
    "\n",
    "Half_Goal_cols = ['HTHG', 'HTAG']\n",
    "Full_Goal_cols = ['FTHG', 'FTAG']\n",
    "Goal_cols = Half_Goal_cols + Full_Goal_cols\n",
    "Result_cols = ['HTR', 'FTR']    # A function of Goal_cols, but contribute to better representation.\n",
    "Shoot_cols = ['HS', 'AS']\n",
    "ShootT_cols = ['HST', 'AST']\n",
    "Corner_cols = ['HC', 'AC']\n",
    "Faul_cols = ['HF', 'AF']\n",
    "Yellow_cols = ['HY', 'AY']    # H/A Yellow Cards, H/A Red Cards\n",
    "Red_cols = ['HR', 'AR']    # H/A Yellow Cards, H/A Red Cards\n",
    "AB_cols = Goal_cols + Result_cols + Shoot_cols + ShootT_cols + Corner_cols + Faul_cols + Yellow_cols + Red_cols\n",
    "\n",
    "# underscore_prefixed lists have discontinued columns.\n",
    "BBAB_cols = BB_cols + AB_cols\n",
    "_Cols_List_to_Embedd = [Div_cols, Team_cols, Goal_cols, Result_cols]\n",
    "_Cols_List_to_Standardize = [Odds_cols, Shoot_cols, ShootT_cols, Corner_cols, Faul_cols, Yellow_cols, Red_cols]\n",
    "_Cols_List_for_Label = [Full_Goal_cols, Odds_cols]\n",
    "_Label_cols = Full_Goal_cols + Odds_cols\n",
    "\n",
    "BBAB_cols = BB_cols + AB_cols\n",
    "base_bbab = list(df.loc[df['id'] == 100000, BBAB_cols].iloc[0, :])\n",
    "print(base_bbab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B365H': (3.1630270400481795, 1.4687447460469159, 46.0), 'HS': (11.39694154084398, 4.709404811489129, 43.0), 'HST': (4.815343915343916, 2.759941394538306, 24.0), 'HC': (5.34632855852368, 2.842282967456132, 24.0), 'HF': (11.421925409730287, 3.7612036770331043, 77.0), 'HY': (1.5455413601755066, 1.2348960213340971, 11.0), 'HR': (0.08013937282229965, 0.2855927650445304, 3.0)}\n"
     ]
    }
   ],
   "source": [
    "std_path = os.path.join('./data', 'datasets', id_to_ids_filename + \".json\")\n",
    "std_params = get_standardization_params(df)\n",
    "print(std_params)\n",
    "data_helpers.SaveJsonData(std_params, std_path)\n",
    "std_params = data_helpers.LoadJsonData(std_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\\datasets\\England-200-1e-07-7300-75-0.8-False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_path = os.path.join('./data', 'datasets', id_to_ids_filename)\n",
    "print(ds_path)\n",
    "\n",
    "# ds = generate_dataset_uk(df, id_to_ids, tokenizer_team, std_params)\n",
    "# tf.data.Dataset.save(ds, ds_path)\n",
    "\n",
    "ds = tf.data.Dataset.load(ds_path)\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(ds)\n",
    "train_size = int(TRAIN_PERCENT/100 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_ds = ds.take(train_size)\n",
    "test_ds = ds.skip(train_size)\n",
    "\n",
    "print(len(train_ds), len(test_ds), len(ds), len(ds)-len(train_ds)-len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in train_ds:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_bbas_tensor = get_dummy_bbas_tensor_uk(df, tokenizer_team, std_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_row(baseId, sequence, base_bb, base_label):\n",
    "    try:\n",
    "        seq_len_org = sequence.shape[0]\n",
    "        nMissings = MAX_TOKENS - seq_len_org\n",
    "        if nMissings > 0:\n",
    "            block = tf.stack([dummy_bbas_tensor] * nMissings, axis=0)\n",
    "            sequence = tf.concat([sequence, block], axis=0) \n",
    "        # print(\"sequence 1\", sequence.shape)\n",
    "        # sequence[:, 2] = base[2] - sequence[:, 2]   # get delta days.\n",
    "        base_bb = base_bb[tf.newaxis, :]    # shape: (seq_len = 1, nFeatures)\n",
    "        mask = tf.Variable([1] * seq_len_org + [0] * nMissings, dtype=tf.int32) ## DO NOT USE tf.constant !!! unstable.\n",
    "        mask = mask[:, tf.newaxis] & mask[tf.newaxis, :]\n",
    "        # print('normalize', sequence.shape, base.shape, mask.shape, mask)\n",
    "        # seq_len_org = tf.Variable(seq_len_org, dtype=tf.int32)    #--------------------------------- comeback\n",
    "        return (baseId, sequence, base_bb, base_label, mask, seq_len_org)\n",
    "    except:\n",
    "        print('normalize_row exception')\n",
    "        print('norm 1', sequence.shape, base_bb.shape, base_label.shape, mask.shape, nMissings)\n",
    "        print('norm 2', baseId, sequence, base_label, mask, nMissings)\n",
    "        # return (baseId, sequence, base_bb, base_label, mask, seq_len_org)\n",
    "\n",
    "def prepare_batch(baseId, sequence, base_bb, base_label, mask, seq_len_org):\n",
    "    # target = tf.one_hot(tf.squeeze(tf.cast(base_bbab[:, :, -1], dtype=tf.int32), axis=-1), hyperparams.target_onehot_size)\n",
    "    return (baseId, sequence, base_bb, mask), (base_label, seq_len_org)     # (X, Y)\n",
    "\n",
    "def normalize_dataset(ds):\n",
    "    return (\n",
    "        ds.map(lambda baseId, sequence, base_bb, base_label: tf.py_function(\n",
    "            func=normalize_row,\n",
    "            inp=[baseId, sequence, base_bb, base_label],\n",
    "            Tout=[tf.int32, tf.float32, tf.float32, tf.float32, tf.int32, tf.int32])) #, tf.data.AUTOTUNE == Instability!!!\n",
    "        )\n",
    "\n",
    "def make_train_batches(ds):\n",
    "    return (\n",
    "        ds\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "        .cache()\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        )\n",
    "\n",
    "def make_test_batches(ds):\n",
    "    return (\n",
    "        ds\n",
    "        .batch(BATCH_SIZE)\n",
    "        .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "        .cache()\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\\datasets\\England-200-1e-07-7300-75-0.8-False_train_90\n",
      "1 34870\n"
     ]
    }
   ],
   "source": [
    "train_ds_path = os.path.join('./data', 'datasets', id_to_ids_filename + '_train_' + str(TRAIN_PERCENT))\n",
    "print(train_ds_path)\n",
    "if os.path.exists(train_ds_path):\n",
    "    train_ds = tf.data.Dataset.load(train_ds_path)\n",
    "    print('1', len(train_ds))\n",
    "else:\n",
    "    train_ds = normalize_dataset(train_ds)\n",
    "    tf.data.Dataset.save(train_ds, train_ds_path)\n",
    "    print('2', len(train_ds))\n",
    "\n",
    "train_batches = make_train_batches(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3875\n"
     ]
    }
   ],
   "source": [
    "test_ds_path = os.path.join('./data', 'datasets', id_to_ids_filename + '_test_' + str(TRAIN_PERCENT))\n",
    "if os.path.exists(test_ds_path):\n",
    "    test_ds = tf.data.Dataset.load(test_ds_path)\n",
    "    print('1', len(test_ds))\n",
    "else:\n",
    "    test_ds = normalize_dataset(test_ds)\n",
    "    tf.data.Dataset.save(test_ds, test_ds_path)\n",
    "    print('2', len(test_ds))\n",
    "\n",
    "test_batches = make_test_batches(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(memory, depth):\n",
    "    positions = tf.range(memory.shape[-1], dtype=tf.float32)\n",
    "    fractional_pos = memory * positions    # fractional position: (batch, fractional position #)\n",
    "    depth = depth/2\n",
    "    depths = tf.range(depth, dtype=tf.float32) / depth\n",
    "    depths = tf.pow(10000.0, depths)    # (depth,)\n",
    "    angle_rads = fractional_pos[:, :, tf.newaxis] / depths  # (batch, fractional position #, depth)\n",
    "    # pos_encoding = rearrange([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], 'w b p d -> w h (w t)')\n",
    "    pos_encoding = tf.concat([tf.math.sin(angle_rads), tf.math.cos(angle_rads)], axis=-1)\n",
    "    return pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = tf.ones((100, 200), dtype=tf.float32) * 0.5\n",
    "pos_encoding = positional_encoding(memory, depth=512)\n",
    "# print('pos_encoding', pos_encoding.shape)\n",
    "pos_encoding = pos_encoding[0, :, :]\n",
    "# print(pos_encoding.shape)\n",
    "# Plot the dimensions.\n",
    "plt.pcolormesh(pos_encoding.numpy().T, cmap='RdBu')\n",
    "plt.ylabel('Depth')\n",
    "plt.xlabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['id']\n",
    "Div_cols = ['Div']\n",
    "Date_cols = ['Date']\n",
    "Team_cols = ['HomeTeam', 'AwayTeam']\n",
    "Odds_cols = ['B365H', 'B365D', 'B365A', 'BWH', 'BWD', 'BWA', 'IWH', 'IWD', 'IWA', 'WHH', 'WHD', 'WHA']\n",
    "BB_cols = id_cols + Div_cols + Date_cols + Team_cols + Odds_cols\n",
    "\n",
    "Half_Goal_cols = ['HTHG', 'HTAG']\n",
    "Full_Goal_cols = ['FTHG', 'FTAG']\n",
    "Goal_cols = Half_Goal_cols + Full_Goal_cols\n",
    "Result_cols = ['HTR', 'FTR']    # A function of Goal_cols, but contribute to better representation.\n",
    "Shoot_cols = ['HS', 'AS']\n",
    "ShootT_cols = ['HST', 'AST']\n",
    "Corner_cols = ['HC', 'AC']\n",
    "Faul_cols = ['HF', 'AF']\n",
    "Yellow_cols = ['HY', 'AY']    # H/A Yellow Cards, H/A Red Cards\n",
    "Red_cols = ['HR', 'AR']    # H/A Yellow Cards, H/A Red Cards\n",
    "AB_cols = Goal_cols + Result_cols + Shoot_cols + ShootT_cols + Corner_cols + Faul_cols + Yellow_cols + Red_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, hyperparams, isEncoder=True):\n",
    "    super().__init__()\n",
    "    self.isEncoder = isEncoder\n",
    "    self.division_embedding = tf.keras.layers.Embedding(hyperparams.nDivisions, hyperparams.division_embs, dtype=tf.float32, mask_zero=False) # Learn Unknown\n",
    "    self.team_embedding = tf.keras.layers.Embedding(hyperparams.nTeams, hyperparams.team_embs, dtype=tf.float32, mask_zero=False) # Learn Unknown\n",
    "    self.goal_embedding = tf.keras.layers.Embedding(hyperparams.nGoals, hyperparams.goal_embs, dtype=tf.float32, mask_zero=False) # Learn 0-goal\n",
    "    self.result_embedding = tf.keras.layers.Embedding(hyperparams.nResults, hyperparams.result_embs, dtype=tf.float32, mask_zero=False) # Learn Unknown\n",
    "\n",
    "    self.d_model = hyperparams.d_model\n",
    "    # print(self.d_model)\n",
    "    self.position_permuting_dense = tf.keras.layers.Dense(self.d_model)\n",
    "    self.m365_embedding = tf.keras.layers.Embedding(1, hyperparams.m365_size, mask_zero=False, embeddings_initializer = tf.keras.initializers.Ones())\n",
    "\n",
    "    self.idx_Days = BB_cols.index('Date')\n",
    "    assert self.idx_Days == BBAB_cols.index('Date')\n",
    "\n",
    "  def call(self, x):\n",
    "    (sequence, base_bb, mask) = x # sob = sequence or base_bb\n",
    "    sDays = sequence[:, :, self.idx_Days]\n",
    "    bDays = base_bb[:, :, self.idx_Days]\n",
    "    \n",
    "    # BB_cols = id_cols + Div_cols + Date_cols + Team_cols + Odds_cols\n",
    "    # AB_cols = Goal_cols + Result_cols + Shoot_cols + ShootT_cols + Corner_cols + Faul_cols + Yellow_cols + Red_cols\n",
    "\n",
    "    sob = None\n",
    "    if self.isEncoder:\n",
    "      sob = sequence\n",
    "    else:\n",
    "      sob = base_bb\n",
    "\n",
    "    if self.isEncoder:\n",
    "      # Extract odds to remove them\n",
    "      id, div, days, teams, odds, goals, results, remainder \\\n",
    "      = tf.split(sob, [len(id_cols), len(Div_cols), len(Date_cols), len(Team_cols), len(Odds_cols), len(Goal_cols), len(Result_cols),  -1], axis=-1)\n",
    "      # print('1', remainder[0, 0])\n",
    "    else:\n",
    "      # Extract odds to remove them\n",
    "      id, div, days, teams, odds, remainder \\\n",
    "      = tf.split(sob, [len(id_cols), len(Div_cols), len(Date_cols), len(Team_cols), len(Odds_cols), -1], axis=-1)  \n",
    "      # print('2', remainder[0, 0])  \n",
    "\n",
    "    # print('pe 2.7.1 1', div)\n",
    "    div = self.division_embedding(tf.cast(div, dtype=tf.int32))\n",
    "    div = tf.reshape(div, [div.shape[0], div.shape[1], -1])\n",
    "    # print('pe 2.7.1 1', div)\n",
    "    teams = self.team_embedding(tf.cast(teams, dtype=tf.int32))\n",
    "    teams = tf.reshape(teams, [teams.shape[0], teams.shape[1], -1])\n",
    "    if self.isEncoder:\n",
    "      goals = self.goal_embedding(tf.cast(goals, dtype=tf.int32))\n",
    "      goals = tf.clip_by_value(goals, 0, hyperparams.nGoals)\n",
    "      goals = tf.reshape(goals, [goals.shape[0], goals.shape[1], -1])\n",
    "      results = self.result_embedding(tf.cast(results, dtype=tf.int32))\n",
    "      results = tf.reshape(results, [results.shape[0], results.shape[1], -1])\n",
    "\n",
    "    odds = tf.ones_like(odds, dtype=tf.float32) * 3.3 #---------------- trick to check if odds worked in 'UK.B.A.13-1'\n",
    "    \n",
    "    if self.isEncoder:\n",
    "      concat = [div, teams, goals, results, odds, remainder]\n",
    "    else:\n",
    "      concat = [div, teams, odds, remainder]\n",
    "\n",
    "    sob = tf.concat(concat, axis=-1)\n",
    "    sob = self.position_permuting_dense(sob)\n",
    "\n",
    "    days_ago = tf.cast(bDays - sDays, dtype=tf.float32) if self.isEncoder else tf.cast(bDays - bDays, dtype=tf.float32)\n",
    "    \n",
    "    m365 = self.m365_embedding(tf.zeros_like((hyperparams.m365_size,), dtype=tf.float32)) * hyperparams.initial_m365  # expected shape: (1, hyperparams.remain_365_size)\n",
    "    m365 = tf.squeeze(m365, axis=0)\n",
    "    memory_alpha = tf.math.pow(m365, 1.0/365) # (hyperparams.m365_size,)\n",
    "    memory = tf.math.pow(memory_alpha, days_ago[:, :, tf.newaxis])  # decrease as days_ago increase, if memory <= 1.0 as expected.\n",
    "    memory = tf.reduce_mean(memory, axis=-1)\n",
    "\n",
    "    pe = positional_encoding(memory, depth=sob.shape[-1]) # (batch, d_model)\n",
    "    pe = pe / tf.math.sqrt(tf.cast(sob.shape[-1], tf.float32))\n",
    "    sob = sob + pe\n",
    "\n",
    "    if self.isEncoder:\n",
    "      mask = mask\n",
    "    else:\n",
    "      mask = mask[:, 0:sob.shape[1], :]\n",
    "\n",
    "    return (sob, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 200, 152) (48, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "pos = PositionalEmbedding(hyperparams, isEncoder=True)\n",
    "\n",
    "cnt = 2\n",
    "for z in train_batches:\n",
    "    (baseId, sequence, base_bb, mask), (base_label, seq_len_org) = z\n",
    "    cnt -= 1\n",
    "    if cnt == 0: break\n",
    "# print('baseId', baseId)\n",
    "sample_x = (sequence, base_bb, mask)\n",
    "eSob, eMask = pos.call(sample_x)\n",
    "print(eSob.shape, eMask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 200, 152) (48, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "PE = PositionalEmbedding(hyperparams, isEncoder=True)\n",
    "eSob, eMask = PE(sample_x)\n",
    "print(eSob.shape, eMask.shape )\n",
    "del PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 1, 152) (48, 1, 200)\n"
     ]
    }
   ],
   "source": [
    "PE = PositionalEmbedding(hyperparams, isEncoder=False)\n",
    "dSob, dMask = PE(sample_x)\n",
    "print(dSob.shape, dMask.shape )\n",
    "del PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "      super().__init__()\n",
    "      self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "      self.layernorm = tf.keras.layers.LayerNormalization()   # So the default -1 axix is normalized across. No inter-token operatoin.\n",
    "      self.add = tf.keras.layers.Add()\n",
    "\n",
    "class CrossAttention(BaseAttention):\n",
    "    def call(self, x, context, mask):\n",
    "      attn_output, attn_scores = self.mha(\n",
    "          query=x,\n",
    "          key=context,\n",
    "          value=context,\n",
    "          attention_mask=mask,\n",
    "          return_attention_scores=True)\n",
    "    \n",
    "      # Cache the attention scores for plotting later.\n",
    "      self.last_attn_scores = attn_scores\n",
    "      x = self.add([x, attn_output])\n",
    "      x = self.layernorm(x)\n",
    "      return x\n",
    "  \n",
    "class GlobalSelfAttention(BaseAttention): \n",
    "    def call(self, x, mask):\n",
    "      attn_output = self.mha(\n",
    "          query=x,\n",
    "          value=x,\n",
    "          key=x,\n",
    "          attention_mask=mask)    # intentional inter-token operation\n",
    "      x = self.add([x, attn_output])  # token-wise\n",
    "      x = self.layernorm(x)         # normalize across the default -1 axis. No inter-token operatoin.\n",
    "      return x\n",
    "  \n",
    "class CausalSelfAttention(BaseAttention): # mask-agnostic\n",
    "    def call(self, x):\n",
    "      attn_output = self.mha(\n",
    "          query=x,\n",
    "          value=x,\n",
    "          key=x,\n",
    "          use_causal_mask = True)     # look-over mask is generagted and used, in decoder layers\n",
    "      x = self.add([x, attn_output])  # mask-agnostic\n",
    "      x = self.layernorm(x)  # normalize across the default -1 axis. No inter-token operatoin.\n",
    "      return x\n",
    "  \n",
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "      super().__init__()\n",
    "      self.seq = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),    # across -1 axis\n",
    "        tf.keras.layers.Dense(d_model),    # across -1 axis\n",
    "        tf.keras.layers.Dropout(dropout_rate)    # mask-agnostic\n",
    "      ])\n",
    "      self.add = tf.keras.layers.Add()\n",
    "      self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "      x = self.add([x, self.seq(x)])  # mask-agnostic\n",
    "      x = self.layer_norm(x)  # normalize across the default -1 axis. No inter-token operatoin.\n",
    "      return x\n",
    "  \n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "      super().__init__()\n",
    "\n",
    "      self.self_attention = GlobalSelfAttention(\n",
    "          num_heads=num_heads,\n",
    "          key_dim=d_model,\n",
    "          dropout=dropout_rate)\n",
    "\n",
    "      self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x, mask):\n",
    "      # x: (batch, max_tokens, d_model), mask: (batch, max_tokens, max_tokens)\n",
    "      x = self.self_attention(x, mask)\n",
    "      x = self.ffn(x)\n",
    "      return x\n",
    "  \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, hyperparams, dropout_rate=0.1):\n",
    "      super().__init__()\n",
    "\n",
    "      self.d_model = hyperparams.d_model\n",
    "      self.num_layers = hyperparams.num_layers\n",
    "\n",
    "      self.pos_embedding = PositionalEmbedding(hyperparams)\n",
    "\n",
    "      self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "      self.enc_layers = [\n",
    "          EncoderLayer(d_model=hyperparams.d_model,\n",
    "                      num_heads=hyperparams.num_heads,\n",
    "                      dff=hyperparams.d_model * 4,\n",
    "                      dropout_rate=dropout_rate)\n",
    "          for _ in range(hyperparams.num_layers)]\n",
    "\n",
    "    def call(self, x):\n",
    "      # x = (sequence, base_bb, mask)\n",
    "      # x[0]: (batch, max_tokens, bbab.len), x[1]: (batch, 1, bb.len), x[2]: (token, max_tokens, max_tokens)\n",
    "      x, mask = self.pos_embedding(x)  # x: (batch, max_tokens, d_model), mask: (batch, max_tokens, max_tokens)\n",
    "      x = self.dropout(x)\n",
    "      for encoder_layer in self.enc_layers:\n",
    "        x = encoder_layer(x, mask)\n",
    "      return x  # Shape `(batch_size, seq_len, d_model)`.\n",
    "  \n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                *,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dff,\n",
    "                dropout_rate=0.1):\n",
    "      super(DecoderLayer, self).__init__()\n",
    "\n",
    "      self.causal_self_attention = CausalSelfAttention(\n",
    "          num_heads=num_heads,\n",
    "          key_dim=d_model,\n",
    "          dropout=dropout_rate)\n",
    "      \n",
    "      self.cross_attention = CrossAttention(\n",
    "          num_heads=num_heads,\n",
    "          key_dim=d_model,\n",
    "          dropout=dropout_rate)\n",
    "\n",
    "      self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "    def call(self, x, context, cross_attention_mask):\n",
    "      # x: (batch, 1, d_model), context: (batch, max_tokens, d_mode)\n",
    "      x = self.causal_self_attention(x=x)\n",
    "      x = self.cross_attention(x, context, cross_attention_mask)\n",
    "\n",
    "      # Cache the last attention scores for plotting later\n",
    "      self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "      x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "      return x\n",
    "  \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, hyperparams, dropout_rate=0.1):\n",
    "      super(Decoder, self).__init__()\n",
    "\n",
    "      self.d_model = hyperparams.d_model\n",
    "      self.num_layers = hyperparams.num_layers\n",
    "\n",
    "      self.pos_embedding = PositionalEmbedding(hyperparams, isEncoder=False)\n",
    "\n",
    "      self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "      self.dec_layers = [\n",
    "          DecoderLayer(d_model=hyperparams.d_model, num_heads=hyperparams.num_heads,\n",
    "                      dff=hyperparams.d_model * 4, dropout_rate=dropout_rate)\n",
    "          for _ in range(hyperparams.num_layers)]\n",
    "\n",
    "      self.last_attn_scores = None\n",
    "\n",
    "    def call(self, x, context):\n",
    "      # x = (sequence, base_bb, mask)\n",
    "      # x[0]: (batch, max_tokens, bbab.len), x[1]: (batch, 1, bb.len), x[2]: (token, max_tokens, max_tokens)\n",
    "      # context: (batch, max_tokens, d_model)\n",
    "      # `x` is token-IDs shape (batch, target_seq_len)\n",
    "      x, ca_mask = self.pos_embedding(x)  # x: (batch, 1, d_model), ca_mask: (batch, 1, max_tokens)     \n",
    "      x = self.dropout(x)\n",
    "      for decoder_layer in self.dec_layers:\n",
    "        x  = decoder_layer(x, context, ca_mask)\n",
    "      self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "      return x\n",
    "  \n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, hyperparams, dropout_rate=0.1):\n",
    "      super().__init__()\n",
    "      self.encoder = Encoder(hyperparams, dropout_rate=dropout_rate)\n",
    "\n",
    "      self.decoder = Decoder(hyperparams, dropout_rate=dropout_rate)\n",
    "\n",
    "      self.final_layer = tf.keras.layers.Dense(hyperparams.d_model) #-------------- to modify\n",
    "\n",
    "    def call(self, inputs):\n",
    "      # inputs = (sequence, base_bb, mask)\n",
    "      # sequence: (batch, max_token, aabb), base: (batch, 1, bb), mask: (batch, max_token, max_token)\n",
    "      x = self.encoder(inputs)  # (batch, max_tokens, d_model)\n",
    "      x = self.decoder(inputs, x)  # (batch, 1, d_model)\n",
    "      logits = self.final_layer(x)  # (batch, 1, d_model)\n",
    "      logits = tf.squeeze(logits, axis=-2)  # (batch, d_model)\n",
    "      return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Encoder)           multiple                  4490487   \n",
      "                                                                 \n",
      " decoder (Decoder)           multiple                  7831087   \n",
      "                                                                 \n",
      " dense_29 (Dense)            multiple                  23256     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,344,830\n",
      "Trainable params: 12,344,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_transformer = Transformer(hyperparams)\n",
    "y = sample_transformer(sample_x)\n",
    "\n",
    "sample_transformer.summary()\n",
    "del sample_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adaptor(tf.keras.layers.Layer):\n",
    "  def __init__(self, nLayers, d_output, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    dims = [hyperparams.d_model + round( (d_output - hyperparams.d_model) * (layer+1) / (nLayers) ) for layer in range(nLayers)]\n",
    "    layers = [tf.keras.layers.Dense(dim, activation='relu') for dim in dims]\n",
    "    self.seq = tf.keras.Sequential(layers)\n",
    "  def call(self, x):\n",
    "    x = self.seq(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGroup(tf.keras.Model):\n",
    "  softmax = tf.keras.layers.Softmax(axis=-1)\n",
    "  scalar_product = tf.keras.layers.Dot(axes=(-1, -1))\n",
    "\n",
    "  def __init__(self, bookie, nQueries, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.bookie = bookie\n",
    "    self.nQueries = nQueries\n",
    "    self.bookieBase = Adaptor(7, self.nQueries) # 7777777777777777777777777\n",
    "    self.oh_1 = Adaptor(5, self.nQueries)       # 5555555555555555555555555\n",
    "    return\n",
    "\n",
    "  def call(self, input):\n",
    "    # inputs.shape: (batch, d_model)\n",
    "    base = self.bookieBase(input)        # (batch, nQueries)\n",
    "    stake_p = QGroup.softmax(base)            # (batch, nQueries)\n",
    "    oh_1_p = self.oh_1(base)                  # (batch, nQueries)\n",
    "    return (oh_1_p, stake_p)  # (batch, 3), (batch, nQueries) \n",
    "\n",
    "  #------------------------------- call used in UK.B.A.01 -------------------------  \n",
    "  # def call(self, input):\n",
    "  #   # inputs.shape: (batch, d_model)\n",
    "  #   base = self.bookieBase(input)        # (batch, nQueries)\n",
    "  #   stake_p = QGroup.softmax(base)            # (batch, nQueries)\n",
    "  #   oh_1_p = self.oh_1(base)                  # (batch, nQueries)\n",
    "  #   profit_p = tf.math.multiply(oh_1_p, stake_p)   # (batch, nQueries)\n",
    "  #   return (profit_p, stake_p)  # (batch, nQueries), (batch, nQueries) \n",
    "\n",
    "  #------------------------------- call in UK.B.A.02, this version -----------\n",
    "  # def call(self, input):\n",
    "  #   # inputs.shape: (batch, d_model)\n",
    "  #   base = self.bookieBase(input)             # (batch, nQueries)\n",
    "  #   stake_p = QGroup.softmax(base)            # (batch, nQueries)\n",
    "  #   oh_1_p = self.oh_1(base)                  # (batch, nQueries)\n",
    "  #   profit_p = self.scalar_product([oh_1_p, stake_p]) # (batch, 1)\n",
    "  #   return (profit_p, stake_p)  # (batch, 1), (batch, nQueries) \n",
    "  \n",
    "  #------------------------------- call in UK.B.A.03, a futrue version -----------\n",
    "  # # profit_p is free and independent of stake_p\n",
    "  # def call(self, input):\n",
    "  #   # inputs.shape: (batch, d_model)\n",
    "  #   base = self.bookieBase(input)             # (batch, nQueries)\n",
    "  #   stake_p = QGroup.softmax(base)            # (batch, nQueries)\n",
    "  #   profit_p = self.profit(base)              # (batch, 1)\n",
    "  #   return (profit_p, stake_p)  # (batch, 1), (batch, nQueries) \n",
    "\n",
    "  #----- ToDo: replace self.scalar_product layer with a tf scalar product function, for speed.\n",
    "  def h_true(self, ftGoals):  # Defines this QGroup. This is for 1X2 QGroup. Derived classes re-define this funciton.\n",
    "    # ftGoals:  (batch, 2)\n",
    "    ftGoals = tf.cast(ftGoals, dtype=tf.int32)  # (batch, 2)\n",
    "    h = (tf.math.greater(ftGoals[..., 0], ftGoals[..., 1]), tf.math.equal(ftGoals[..., 0], ftGoals[..., 1]), tf.math.less(ftGoals[..., 0], ftGoals[..., 1]))\n",
    "    h = tf.cast(tf.transpose(h), dtype=tf.float32)  # (batch, nQueries)\n",
    "    return h\n",
    "\n",
    "  def profit_true(self, ftGoals, odds):\n",
    "    stake_t = self.h_true(ftGoals)  # (batch, nQueries)\n",
    "    oh_1_true = tf.math.multiply(odds, self.h_true(ftGoals)) - 1.0  # (batch, nQueries)\n",
    "    profit_t = self.scalar_product([oh_1_true, stake_t])  # (batch, 1)\n",
    "    return profit_t\n",
    "\n",
    "  #-------------------- THis loss is NOT used in action versions.\n",
    "  def loss(self, profit_p, stake_p, ftGoals, odds, rambda):\n",
    "    # profit_p: (batch, 1)\n",
    "    # stake_p:  (batch, nQueries)\n",
    "    # ftGoals:  (batch, 2)\n",
    "    # odds:     (batch, nQueries)\n",
    "    # rambda:   ()\n",
    "    profit_t = self.profit_true(ftGoals, odds)  # (batch, 1)\n",
    "    if MAE_NOT_MSE_LOSS:\n",
    "        profit_p_err = tf.reduce_mean(tf.math.abs(profit_t - profit_p), axis=None) # (), profit dimention.\n",
    "    else:\n",
    "        profit_p_err = tf.reduce_mean(tf.math.pow(profit_t - profit_p, 2.0), axis=None) # (), profit dimention.\n",
    "\n",
    "    oh_1_t = tf.math.multiply(odds, self.h_true(ftGoals)) - 1.0   # (batch, nQueries)\n",
    "    profit_back = self.scalar_product([oh_1_t, stake_p])    # (batch, 1)\n",
    "    profit_back = tf.reduce_mean(profit_back, axis=None)    # ()\n",
    "    loss = (1.0-rambda) * profit_p_err - profit_back * rambda # ()\n",
    "    return loss # ()\n",
    "  \n",
    "  def oh_1_loss(self, oh_1_p, ftGoals, odds):\n",
    "    # oh_1_p: (bacth, nQueries)\n",
    "    h_true = self.h_true(ftGoals)\n",
    "    oh_1_t = tf.multiply(odds, h_true)  # (batch, nQueries)\n",
    "    if MAE_NOT_MSE_LOSS:\n",
    "        profit_p_err = tf.reduce_mean(tf.math.abs(oh_1_t - oh_1_p), axis=-1) # (batch, ), profit dimention.\n",
    "    else:\n",
    "        profit_p_err = tf.reduce_mean(tf.math.pow(oh_1_t - oh_1_p, 2.0), axis=-1) # (batch, ), profit dimention.\n",
    "    \n",
    "    return profit_p_err # (batch, )\n",
    "\n",
    "  #--------------------------------------- Used as profit_back_with_batch in UK.B.A.01\n",
    "  def profit_eval(self, ftGoals, odds, stake_p):\n",
    "    oh_1_t = tf.math.multiply(odds, self.h_true(ftGoals)) - 1.0\n",
    "    profit_e = QGroup.scalar_product([oh_1_t, stake_p])\n",
    "    return profit_e   # (batch, 1)\n",
    "\n",
    "  #-------------------------------------- The same as 'profit_eval' above --------------\n",
    "  def profit_back_with_batch(self, ftGoals, odds, stake_p):\n",
    "    oh_1_t = tf.math.multiply(odds, self.h_true(ftGoals)) - 1.0\n",
    "    profit_back = self.scalar_product([oh_1_t, stake_p])    # (batch, 1)\n",
    "    return profit_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[3.0, 3.0, 4.0], [0.1, 0.7, 0.3]])\n",
    "one_hot_a = tf.squeeze(tf.one_hot(tf.nn.top_k(a).indices, tf.shape(a)[-1]), axis=1)\n",
    "print(one_hot_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QGroup1X2(QGroup):\n",
    "  def __init__(self, bookie, dropout_rate=0.1):\n",
    "    super().__init__(bookie=bookie, nQueries=3, dropout_rate=dropout_rate)\n",
    "    self.qGroupName = '1X2'\n",
    "\n",
    "  def h_true(self, ftGoals):  # Defines this QGroup. This is for 1X2 QGroup.\n",
    "    # ftGoals:  (batch, 2)\n",
    "    ftGoals = tf.cast(ftGoals, dtype=tf.int32)  # (batch, 2)\n",
    "    h = (tf.math.greater(ftGoals[..., 0], ftGoals[..., 1]), tf.math.equal(ftGoals[..., 0], ftGoals[..., 1]), tf.math.less(ftGoals[..., 0], ftGoals[..., 1]))\n",
    "    h = tf.cast(tf.transpose(h), dtype=tf.float32)  # (batch, nQueries)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BettingEPL(tf.keras.Model):\n",
    "  def __init__(self, hyperparams, loss_rambda=1.0, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.transformer = Transformer(hyperparams, dropout_rate=dropout_rate)\n",
    "    self.bookies = ['B365', 'Betfair', 'Interwetten', 'William']\n",
    "    self.qGroups = [QGroup1X2(bookie) for bookie in self.bookies]\n",
    "    self.rambda = loss_rambda     #----------------------- Sensitive rambda!!!, Automate optimizing it.\n",
    "    # self.shift_embedding = tf.keras.layers.Embedding(1, hyperparams.m365_size, mask_zero=False, embeddings_initializer = tf.keras.initializers.Ones())\n",
    "    # self.shift = None\n",
    "\n",
    "  def call(self, input):\n",
    "      x = self.transformer(input)\n",
    "      outputs = [qGroup(x) for qGroup in self.qGroups]\n",
    "      # self.shift = tf.squeeze(self.shift_embedding(0))  # squeeze((1, 1)) = ()\n",
    "      return outputs  # [ ( shape: (batch, 1), shape: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "  \n",
    "  def loss(self, y, outputs):   \n",
    "      # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "      # outputs: # [ ( profit_p: (batch, 1), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "      ftGoals, odds = tf.split(y, [2, -1], axis=-1) # (batch, 2), (batch, sum[qGropu.nQueries for qGroup in self.qGroups])\n",
    "      odds_by_qGroup = tf.split(odds, [qQroup.nQueries for qQroup in self.qGroups], axis=-1)  # [ shape: (batch, qGroup.nQueries) for qGroup in self.qGroups ]\n",
    "      losses = [qGroup.loss(profit_p, stake_p, ftGoals, odds, self.rambda) for (qGroup, odds, (profit_p, stake_p)) in zip(self.qGroups, odds_by_qGroup, outputs)]\n",
    "      # losses: [()] * nQGroup\n",
    "      losses = tf.stack(losses, axis=0) # (nQGroups,)\n",
    "      loss_value = tf.math.mean_reduce(losses, axis=None)\n",
    "      return loss_value\n",
    "  \n",
    "  def profit_back_over_qGroups(self, y, outputs):\n",
    "      # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "      # outputs: # [ ( oh_1_p: (batch, nQueries), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "      ftGoals, odds = tf.split(y, [2, -1], axis=-1)\n",
    "      odds_by_qGroup = tf.split(odds, [qQroup.nQueries for qQroup in self.qGroups], axis=-1)\n",
    "      profit_back = [qGroup.profit_back_with_batch(ftGoals, odds, stake_p) for (qGroup, odds, (_, stake_p)) in zip(self.qGroups, odds_by_qGroup, outputs)]\n",
    "      # profit_back = [(batch, 1) for _ in self.qGroups]\n",
    "      profit_back = tf.concat(profit_back, axis=-1) # (batch, nQGroups)\n",
    "      return profit_back  # A function of stake_p and truth.\n",
    "  \n",
    "  #---------------------------------- The same as in UK.B.A.01, with a bit of code factorization.\n",
    "  def action_loss(self, y, outputs, selectivity):\n",
    "      # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "      # outputs: # [ ( oh_1_p: (batch, nQueries), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "      ftGoals, odds = tf.split(y, [2, -1], axis=-1) # (batch, 2), (batch, sum[qGropu.nQueries for qGroup in self.qGroups])\n",
    "      odds_by_qGroup = tf.split(odds, [qQroup.nQueries for qQroup in self.qGroups], axis=-1)  # [ shape: (batch, qGroup.nQueries) for qGroup in self.qGroups ]\n",
    "      oh_1_loss = [qGroup.oh_1_loss(oh_1_p, ftGoals, odds) for (qGroup, odds, (oh_1_p, _)) in zip(self.qGroups, odds_by_qGroup, outputs)] # [(batch,)] * nQGroups\n",
    "      oh_1_loss = tf.stack(oh_1_loss, axis=-1)  # sure (batch, nQGroups)\n",
    "      oh_1_loss = tf.math.reduce_mean(oh_1_loss, axis=None)  # ()\n",
    "      \n",
    "      profit_p = [tf.math.reduce_sum(tf.multiply(oh_1_p, stake_p), axis=-1, keepdims=True) for (oh_1_p, stake_p) in outputs]   # [ shape: (batch, 1) for _ self.qGroups ]\n",
    "      profit_p = tf.concat(profit_p, axis=-1) # (batch, nQGroups)\n",
    "\n",
    "      #======================================================================================================\n",
    "      #   This block simulates the betting action of selecting QGROUP where profit_p is high..\n",
    "      #   Note argmax-based selecting has no gradient.\n",
    "      #======================================================================================================\n",
    "      # least_profit = tf.reduce_min(profit_p, axis=-1)\n",
    "      # delta = tf.reduce_max(profit_p, axis=-1) - least_profit\n",
    "      # normal_profit = tf.transpose(tf.transpose(profit_p) - least_profit)\n",
    "      # normal_profit = tf.transpose(tf.transpose(normal_profit)/(delta + 1e-9)) # no tf.keras.backend.epsilon\n",
    "      # is_zero = ((1.0 - tf.reduce_max(normal_profit, axis=1)))\n",
    "      # normal_profit = tf.transpose(tf.transpose(normal_profit) + is_zero) # (batch, nQGroups). A function of profit_p     \n",
    "      # normal_profit = normal_profit * selectivity + 1.0  # self.shift\n",
    "      \n",
    "      #======================================================================================================\n",
    "      #   This block simulates the betting action of selecting games and qGroups where profit_p is high..\n",
    "      #   Note argmax-based selecting has no gradient.\n",
    "      #======================================================================================================\n",
    "      profit_read = tf.identity(profit_p)\n",
    "      min = tf.reduce_min(profit_read); max = tf.reduce_max(profit_read)\n",
    "      normal_profit = (profit_read - min) / (max-min + 1e-12) * selectivity # (batch,)   [0, 1]\n",
    "      normal_profit = normal_profit + 1.0\n",
    "\n",
    "      profit_back = self.profit_back_over_qGroups(y, outputs) # (batch, nQGroups) # A function of stake_p and truth.\n",
    "\n",
    "      mul = tf.multiply(normal_profit, profit_back)   # (batch, nQGroups)\n",
    "      mean_profit_per_game = tf.math.reduce_mean(mul, axis=None)  # ()\n",
    "      \n",
    "      return  (- mean_profit_per_game + oh_1_loss)\n",
    "\n",
    "  #---------------------------------- The same as in UK.B.A.01, with a bit of code factorization.\n",
    "  def back_test(self, y, outputs):\n",
    "    # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "    # outputs: # [ ( shape: (batch, 1), shape: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "    profit_back = self.profit_back_over_qGroups(y, outputs) # (batch, nQGroups)\n",
    "\n",
    "    # find the most-profitable QGroup idx\n",
    "    profits_p = [tf.math.reduce_sum(profit_p, axis=-1, keepdims=True) for (profit_p, _) in outputs]   # [ shape: (batch, 1) for _ self.qGroups ]\n",
    "    profits_p = tf.concat(profits_p, axis=-1) # (batch, len(self.qGroups))    \n",
    "    bestQuery = tf.cast(tf.argmax(profits_p, axis=-1), dtype=tf.int32)   # (batch,)\n",
    "    range = tf.range(bestQuery.shape[0], dtype=tf.int32) # (batch,)\n",
    "    best_idx = tf.stack([range, bestQuery], axis=1) # (batch, 2)\n",
    "    \n",
    "    best_profits_eval = tf.gather_nd(profit_back, best_idx)  # (batch, )\n",
    "    profit_eval_mean = tf.math.reduce_mean(best_profits_eval)\n",
    "    return profit_eval_mean\n",
    "  \n",
    "  def back_test_over_chosen_games_and_qGroups(self, y, outputs):\n",
    "    # Choose (game, qGroup), which is greater than 0.05, or MIN_PROFIT_P_PER_GAME_PER_QGROUP\n",
    "    # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "    # outputs: # [ ( oh_1_p: (batch, nQueries), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "    profit_p = [tf.math.multiply(p_p, s_p) for (p_p, s_p) in outputs]  # [ (batch, nQueries) ] * nQGroups\n",
    "    profit_p = [tf.math.reduce_sum(p_p, axis=-1, keepdims=True) for p_p in profit_p] # [(batch, 1)] * nQGroups\n",
    "    profit_p = tf.concat(profit_p, axis=-1)   # (batch, nQGroups))\n",
    "    profit_back = self.profit_back_over_qGroups(y, outputs)   # (batch, nQGroups)\n",
    "\n",
    "    best_idx = tf.where(profit_p > MIN_PROFIT_P_PER_GAME_PER_QGROUP)  # (nBettings, 2). nBettings unknown yet.\n",
    "\n",
    "    nBettings = 0\n",
    "    profit_back_mean_per_betting = MIN_PROFIT\n",
    "    if best_idx.shape[0] > 0:\n",
    "      best_profits_back = tf.gather_nd(profit_back, best_idx)   # (nBettings, )\n",
    "      nBettings = best_profits_back.shape[0]\n",
    "      profit_back_mean_per_betting = tf.math.reduce_mean(best_profits_back)\n",
    "    return profit_back_mean_per_betting, nBettings\n",
    "  \n",
    "  def back_test_over_chosen_games_and_qGroups_for_distribution(self, y, outputs, keys):\n",
    "    # Choose (game, qGroup), which is greater than 0.05, or MIN_PROFIT_P_PER_GAME_PER_QGROUP\n",
    "    # y: (batch, len(Team_cols)+len(Odds_cols)) \n",
    "    # outputs: # [ ( oh_1_p: (batch, nQueries), stake_p: (batch, nQueries) ) for _ in self.qGroups ]\n",
    "    profit_p = [tf.math.multiply(p_p, s_p) for (p_p, s_p) in outputs]  # [ (batch, nQueries) ] * nQGroups\n",
    "    profit_p = [tf.math.reduce_sum(p_p, axis=-1, keepdims=True) for p_p in profit_p] # [(batch, 1)] * nQGroups\n",
    "    profit_p = tf.concat(profit_p, axis=-1)   # (batch, nQGroups))\n",
    "    profit_back = self.profit_back_over_qGroups(y, outputs)   # (batch, nQGroups)\n",
    "\n",
    "    profit_back_mean_per_betting_list = []\n",
    "    nBettings_list = []\n",
    "\n",
    "    for key in keys:\n",
    "      best_idx = tf.where(profit_p > key)  # (nBettings, 2). nBettings unknown yet.\n",
    "\n",
    "      nBettings = 0\n",
    "      profit_back_mean_per_betting = MIN_PROFIT\n",
    "      if best_idx.shape[0] > 0:\n",
    "        best_profits_back = tf.gather_nd(profit_back, best_idx)   # (nBettings, )\n",
    "        nBettings = best_profits_back.shape[0]\n",
    "        profit_back_mean_per_betting = tf.math.reduce_mean(best_profits_back)\n",
    "      profit_back_mean_per_betting_list.append(float(profit_back_mean_per_betting))\n",
    "      nBettings_list.append(nBettings)\n",
    "    return profit_back_mean_per_betting_list, nBettings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[3.0, 3.0, 4.0], [0.1, 0.7, 0.3]])\n",
    "one_hot_a = tf.squeeze(tf.one_hot(tf.nn.top_k(a).indices, tf.shape(a)[-1]), axis=1)\n",
    "print(one_hot_a)\n",
    "# one_hot_a = [[ 0.  0.  1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n",
      "(48, 3) (48, 3)\n",
      "Model: \"betting_epl\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer_1 (Transformer)  multiple                 12344830  \n",
      "                                                                 \n",
      " q_group1x2 (QGroup1X2)      multiple                  74282     \n",
      "                                                                 \n",
      " q_group1x2_1 (QGroup1X2)    multiple                  74282     \n",
      "                                                                 \n",
      " q_group1x2_2 (QGroup1X2)    multiple                  74282     \n",
      "                                                                 \n",
      " q_group1x2_3 (QGroup1X2)    multiple                  74282     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,641,958\n",
      "Trainable params: 12,641,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPL = BettingEPL(hyperparams, loss_rambda = LOSS_RAMBDA, dropout_rate=TRANSFORMER_DROP)\n",
    "\n",
    "x = (sequence, base_bb, mask)\n",
    "y = EPL(sample_x, training=True)\n",
    "print(len(y))\n",
    "print(len(y[0]))\n",
    "(profit_p, stake_p) = y[0]\n",
    "print(profit_p.shape, stake_p.shape)\n",
    "# print(profit_p, stake_p)   # profit_p tend to have the same sign in the same batch.\n",
    "# shift = tf.squeeze(EPL.layers[-1].get_weights()).numpy()\n",
    "# print('shift', shift)\n",
    "\n",
    "EPL.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = CustomSchedule(hyperparams.d_model)\n",
    "\n",
    "learning_rate = LEARNING_RATE\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.95, beta_2=0.95, epsilon=1e-9)\n",
    "# optimizer = tf.keras.optimizers.Adadelta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def masked_loss_uk(label, y_pred):\n",
    "  # lable = (target(batch, 3), base_bb(batch, 1, 9), seq_len(batch, 1)), y_pred: (batch, 3)\n",
    "  y_true = label[0]   # one_hot: (batch, 3)\n",
    "  seq_len = label[2]  # (batch, 1)\n",
    "\n",
    "  mask = y_true != 0 \n",
    "  loss = loss_object(y_true, y_pred)\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask) # eq. sum_loss / batch\n",
    "  return loss\n",
    "\n",
    "\n",
    "class recall():\n",
    "  def __init__(self, name='recall', min_seq_len=5, **kwargs):\n",
    "    self.min_seq_len = min_seq_len\n",
    "    self.n = None\n",
    "    self.recall = None\n",
    "    self.reset()\n",
    "\n",
    "  def update_state(self, label, y_pred):\n",
    "    # lable = (target(batch, 3), base_bb(batch, 1, 9), seq_len(batch,)), y_pred: (batch, 3)\n",
    "    y_true = label[0]   # one_hot: (batch, 3)\n",
    "    seq_len = label[2]  # (batch)\n",
    "\n",
    "    seq_len_mask = tf.cast(seq_len >= self.min_seq_len, dtype=tf.float32)[:, tf.newaxis, tf.newaxis]\n",
    "    y_true = y_true * seq_len_mask\n",
    "    y_pred = y_pred * seq_len_mask \n",
    "\n",
    "    # print('recall', y_true.shape, y_pred.shape, seq_len_mask.shape)\n",
    "\n",
    "    true_positives = tf.math.reduce_sum(y_true * y_pred)\n",
    "    # print('recall', true_positives.numpy())\n",
    "    possible_positives = tf.math.reduce_sum(y_true)\n",
    "    recall_keras = true_positives / (possible_positives + 1e-9) #tf.keras.backend.epsilon())\n",
    "    self.n += 1\n",
    "    self.recall = self.recall * (self.n-1)/self.n + recall_keras.numpy() / self.n\n",
    "\n",
    "\n",
    "  def result(self):\n",
    "    return self.recall\n",
    "  \n",
    "  def reset(self):\n",
    "    self.n = 0\n",
    "    self.recall = 0.0\n",
    "  \n",
    "recall_object = recall(min_seq_len=5)\n",
    "\n",
    "class precision():\n",
    "  def __init__(self, name='precision', min_seq_len=5, **kwargs):\n",
    "    self.min_seq_len = min_seq_len\n",
    "    self.n = None\n",
    "    self.precision = None\n",
    "    self.reset()\n",
    "\n",
    "  def update_state(self, label, y_pred):\n",
    "    # lable = (target(batch, 3), base_bb(batch, 1, 9), seq_len(batch,)), y_pred: (batch, 3)\n",
    "    y_true = label[0]   # one_hot: (batch, 3)\n",
    "    seq_len = label[2]  # (batch, 1)\n",
    "\n",
    "    seq_len_mask = tf.cast(seq_len >= self.min_seq_len, dtype=tf.float32)[:, tf.newaxis, tf.newaxis]\n",
    "    y_true = y_true * seq_len_mask\n",
    "    y_pred = y_pred * seq_len_mask \n",
    "\n",
    "    true_positives = tf.math.reduce_sum(y_true * y_pred)\n",
    "    predicted_positives = tf.math.reduce_sum(y_pred)\n",
    "    precision_keras = true_positives / (predicted_positives + 1e-9) #tf.keras.backend.epsilon())\n",
    "    self.n += 1\n",
    "    self.precision = self.precision * (self.n-1)/self.n + precision_keras.numpy() / self.n\n",
    "\n",
    "  def result(self):\n",
    "    return self.precision\n",
    "  \n",
    "  def reset(self):\n",
    "    self.n = 0\n",
    "    self.precision = 0.0\n",
    "\n",
    "precision_object = precision(min_seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y, selectivity):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = EPL(x, training=True)  # [ (batch, 1), (batch, nQueries) for _ in bookies]\n",
    "        loss_value = EPL.action_loss(y, outputs, selectivity)\n",
    "    \n",
    "    grads = tape.gradient(loss_value, EPL.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, EPL.trainable_weights))\n",
    "    # recall_object.update_state(y, logits)\n",
    "    # precision_object.update_state(y, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(x, y, selectivity):\n",
    "    outputs = EPL(x, training=False)  # [ (batch, 1), (batch, nQueries) for _ in bookies]\n",
    "    loss_value = EPL.action_loss(y, outputs, selectivity)\n",
    "    # recall_object.update_state(y, val_logits)\n",
    "    # precision_object.update_state(y, val_logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function  # gives a wrong result of tf.where(profit_p > MIN_PROFIT_P_PER_GAME_PER_QGROUP)\n",
    "def back_test_step(x, y):\n",
    "    outputs = EPL(x, training=False)  # [ (batch, 1), (batch, nQueries) for _ in bookies]\n",
    "    profit_back_mean_per_betting, nBettings = EPL.back_test_over_chosen_games_and_qGroups(y, outputs)\n",
    "    return profit_back_mean_per_betting, nBettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function  #-------------------- Wierd: no work.\n",
    "def back_test_with_dataset(datsset):\n",
    "    profit_back_mean = 0.0\n",
    "    nBettingsTotal = 0\n",
    "    for step, ((baseId, sequence, base_bb, mask), (base_label, seq_len_org)) in enumerate(datsset):\n",
    "        x = (sequence, base_bb, mask); y = base_label\n",
    "        profit_back_mean_per_betting, nBettings = back_test_step(x, y)\n",
    "        # print('back_test_with_dataset', profit_back_mean_per_betting, nBettings)\n",
    "        if nBettings > 0:\n",
    "            profit_back_mean = (profit_back_mean * nBettingsTotal + profit_back_mean_per_betting * nBettings) / (nBettingsTotal + nBettings)\n",
    "            nBettingsTotal = nBettingsTotal + nBettings\n",
    "    return profit_back_mean, nBettingsTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15500\n"
     ]
    }
   ],
   "source": [
    "# @tf.function  #-------------------- Wierd: no work.\n",
    "def back_test_with_dataset_for_max_nBettings(datsset):\n",
    "    nBettingsTotal = 0\n",
    "    for step, ((baseId, sequence, base_bb, mask), (base_label, seq_len_org)) in enumerate(datsset):\n",
    "        nBettingsTotal = nBettingsTotal + sequence.shape[0] * 4\n",
    "    return nBettingsTotal\n",
    "print(back_test_with_dataset_for_max_nBettings(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function  #-------------------- Wierd: no work.\n",
    "def test_with_dataset(datsset, selectivity):\n",
    "    n = 0\n",
    "    val_loss = tf.Variable(0.0, dtype=tf.float32)\n",
    "    for step, ((baseId, sequence, base_bb, mask), (base_label, seq_len_org)) in enumerate(datsset):\n",
    "        x = (sequence, base_bb, mask); y = base_label\n",
    "        n += 1\n",
    "        val_loss = val_loss * (n-1) / n + test_step(x, y, selectivity) / n   ###\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class history_class():\n",
    "    def round_sig(self, x, sig=2):\n",
    "            return x\n",
    "            # return round(x, sig-int(math.floor(math.log10(abs(x))))-1)    # domain error for VERY small numbers.\n",
    "    def __init__(self):\n",
    "        self.history = {'loss': [], 'val_loss': [], 'back100': [], 'nBettings': []}\n",
    "    def save(self, path):\n",
    "        data_helpers.SaveJsonData(self.history, path)\n",
    "    def load(self, path):\n",
    "        self.history = data_helpers.LoadJsonData(path)\n",
    "        if self.history is None:\n",
    "            self.history = {'loss': [], 'val_loss': [], 'back100': [], 'nBettings': []}\n",
    "    def to_back100(self, back):\n",
    "        return float(back if back >= 0 else back)\n",
    "    def append(self, loss, val_loss, back, nBettings):\n",
    "        self.history['loss'].append(self.round_sig(float(loss), 4))\n",
    "        self.history['val_loss'].append(self.round_sig(float(val_loss), 4))\n",
    "        self.history['back100'].append(self.round_sig(self.to_back100(back), 4))\n",
    "        self.history['nBettings'].append(int(nBettings))\n",
    "    def len(self):\n",
    "        assert len(self.history['loss']) == len(self.history['val_loss'])\n",
    "        assert len(self.history['loss']) == len(self.history['back100'])\n",
    "        assert len(self.history['loss']) == len(self.history['nBettings'])\n",
    "        return len(self.history['loss'])\n",
    "    def get_latest_item(self):\n",
    "        return (self.history['loss'][-1], self.history['val_loss'][-1], self.history['back100'][-1], self.history['nBettings'][-1])\n",
    "    def get_max_back(self):\n",
    "        return float('-inf') if self.len() <= 0 else max(self.history['back100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_steps(epoch, step, loss, samples_seen):\n",
    "    # recall = recall_object.result()\n",
    "    # precision = precision_object.result()\n",
    "    # print(\"epoch: {}, step: {}, loss: {}, recall: {}, precision: {}, samples_seen: {}\".\n",
    "    #       format(epoch, step, float(loss_value), recall, precision, (step + 1) * hyperparams.batch_size))\n",
    "    print(\"epoch: {}, step: {}, loss: {}, samples_seen: {}          \".\n",
    "            format(epoch, step, float(loss), samples_seen), end='\\r')\n",
    "    # recall_object.reset()\n",
    "    # precision_object.reset()\n",
    "\n",
    "def show_history(history, baseline=0):\n",
    "    plt.figure(figsize=(15,6))\n",
    "\n",
    "    loss = history.history['loss'][baseline:]\n",
    "    val_loss = history.history['val_loss'][baseline:]\n",
    "    losses = loss + val_loss\n",
    "    back = [b100 * 100 for b100 in history.history['back100']][baseline:]\n",
    "    nBettings = history.history['nBettings'][baseline:]\n",
    "    minBack = min(back) if history.len() > 0 else 0.0; maxBack = max(back) if history.len() > 0 else 1.0\n",
    "    minLosses = min(losses) if history.len() > 0 else 0.0; maxLosses = max(losses) if history.len() > 0 else 1.0\n",
    "    loss = [(elem - minLosses) / (maxLosses-minLosses+1e-9) * (maxBack-minBack) + minBack for elem in loss]\n",
    "    val_loss = [(elem - minLosses) / (maxLosses-minLosses+1e-9) * (maxBack-minBack) + minBack for elem in val_loss]\n",
    "    minBettings = min(nBettings) if history.len() > 0 else 0.0; maxBettings = max(nBettings) if history.len() > 0 else 1.0\n",
    "    nBettings = [(elem - minBettings) / (maxBettings-minBettings+1e-9) * (maxBack-minBack) + minBack for elem in nBettings]\n",
    "    base = 0.0\n",
    "\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.plot(back)\n",
    "    plt.plot(nBettings, color='y', linewidth=0.5)\n",
    "    \n",
    "    bestBack = max(back) if history.len() - baseline > 0 else -1.0\n",
    "    bestBackIdx = back.index(bestBack) if back.count(bestBack) > 0 else 0\n",
    "\n",
    "    all = loss + val_loss + back + nBettings\n",
    "    if len(all) > 0:\n",
    "        ymin = min(all); ymax = max(all); xmin = 0; xmax = history.len() - baseline\n",
    "    else:\n",
    "        ymin = 0.0; ymax = 1.0; xmin = 0.0; xmax = 1.0\n",
    "     \n",
    "    plt.axvline(x=bestBackIdx, ymin=ymin, ymax=ymax, color='r', linewidth=0.3)\n",
    "    plt.axhline(y=bestBack, xmin=xmin, xmax=xmax, color='r', linewidth=0.3)\n",
    "    plt.axhline(y=base, color='b', linestyle='-', linewidth=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.title(TEST_ID + \": Avg profit (%) per betting. max: {}, history len: {}\".format(bestBack, history.len()))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train_loss', 'val_loss', '100 * val_profit', 'nBettings'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointPath = os.path.join('./data', 'checkpoints', TEST_ID + '_weights')\n",
    "checkpointPathBest = os.path.join('./data', 'checkpoints', TEST_ID + '_weights_best')\n",
    "historyPath = os.path.join('./data', 'checkpoints', TEST_ID + '_history.json')\n",
    "\n",
    "history = history_class()\n",
    "\n",
    "if RESET_HISTORY:\n",
    "    files = glob.glob(checkpointPath + \"*\")         # \"*.*\" doesn't work\n",
    "    result = [os.remove(file) for file in files]\n",
    "    files = glob.glob(historyPath + \"*\")            # \"*.*\" doens't work\n",
    "    result = [os.remove(file) for file in files]\n",
    "    EPL.save_weights(checkpointPath)    #\n",
    "    history.save(historyPath)\n",
    "\n",
    "try:\n",
    "    EPL.load_weights(checkpointPath)\n",
    "except:\n",
    "    print('Failed to load model weights.')\n",
    "\n",
    "history.load(historyPath)\n",
    "# if history.len() <= 0:\n",
    "#     print('Creating historic baseline...', end='')\n",
    "#     loss = test_with_dataset(train_batches)\n",
    "#     val_loss = test_with_dataset(test_batches)\n",
    "#     back = back_test_with_dataset(test_batches)\n",
    "#     history.append(loss, val_loss, back)\n",
    "#     history.save(historyPath)\n",
    "#     print('done')\n",
    "\n",
    "def save_checkpoint(loss, val_loss, back, nBettings):\n",
    "    EPL.save_weights(checkpointPath)\n",
    "    max_back = history.get_max_back()\n",
    "    if float(history.to_back100(back)) > max_back:\n",
    "        EPL.save_weights(checkpointPathBest)\n",
    "    history.append(loss, val_loss, back, nBettings)\n",
    "    history.save(historyPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7572097778320312, 1.7569999694824219, 1.7568830251693726, 1.7567992210388184, 1.7567342519760132, 1.756697177886963, 1.7566593885421753, 1.756649136543274, 1.756630778312683, 1.7566282749176025, 1.7566171884536743, 1.7566231489181519, 1.7566083669662476, 1.756608486175537, 1.7566038370132446, 1.7566078901290894, 1.756610631942749, 1.756591796875, 1.756604552268982, 1.756589412689209, 1.7565925121307373, 1.7565897703170776, 1.7565962076187134, 1.756583333015442, 1.7565892934799194, 1.7565866708755493, 1.756590723991394, 1.7565946578979492, 1.7565847635269165, 1.7565816640853882, 1.7565932273864746, 1.7565921545028687, 1.756601095199585, 1.7565906047821045, 1.756600260734558, 1.7565860748291016, 1.756590485572815, 1.7565906047821045]\n",
      "[1.7592887878417969, 1.7588967084884644, 1.7585999965667725, 1.7583363056182861, 1.7581582069396973, 1.7580286264419556, 1.7579448223114014, 1.7578661441802979, 1.7578210830688477, 1.7577838897705078, 1.7577558755874634, 1.7577106952667236, 1.7576756477355957, 1.7576608657836914, 1.7576303482055664, 1.7576097249984741, 1.7575907707214355, 1.7575534582138062, 1.7575244903564453, 1.7575178146362305, 1.7575138807296753, 1.757509469985962, 1.7575054168701172, 1.7575035095214844, 1.7575023174285889, 1.7575002908706665, 1.7575002908706665, 1.7575000524520874, 1.7574994564056396, 1.7574989795684814, 1.7574989795684814, 1.7574986219406128, 1.7574986219406128, 1.7574986219406128, 1.7574986219406128, 1.7574986219406128, 1.7574986219406128, 1.7574986219406128]\n",
      "[-0.022507967427372932, -0.019287344068288803, -0.016849100589752197, -0.014683623798191547, -0.013215044513344765, -0.012150000780820847, -0.011459200643002987, -0.010820521041750908, -0.010454329662024975, -0.010143864899873734, -0.009911855682730675, -0.009547756053507328, -0.009260601364076138, -0.009133766405284405, -0.008885863237082958, -0.008716962300240993, -0.008561082184314728, -0.00825482327491045, -0.008021111600100994, -0.007964720018208027, -0.00792866200208664, -0.007898344658315182, -0.007865805178880692, -0.007845847867429256, -0.007832773961126804, -0.007824628613889217, -0.007818412967026234, -0.007813670672476292, -0.007810667157173157, -0.007808662485331297, -0.007807617075741291, -0.007806635461747646, -0.007806150242686272, -0.007805916015058756, -0.0078057399950921535, -0.007805667817592621, -0.007805641274899244, -0.007805620785802603]\n",
      "[46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500, 46500]\n"
     ]
    }
   ],
   "source": [
    "for key, value in history.history.items():\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_history(history, baseline=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule(epoch):\n",
    "    selectivity = 1.0 / NORM_PP_PATIENCY * epoch    # start from 0.05, grow linearly over epoch, and hit 5.0 when epoch == NORM_PP_PATIENCY, which should be about 100.\n",
    "    return selectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (48, 12) step: 726, loss: 1.7486952543258667, samples_seen: 34870          \n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (48, 12)\n",
      "2 576\n",
      "1 (35, 12)\n",
      "2 420\n",
      "epoch: 38, loss: 1.7565906047821045, val_loss: 1.7574986219406128, back_test: -0.007805605884641409, nBettings: 46500, baseId_1: 102048, memory365: 0.9005,  time taken: 198s          \n",
      "epoch: 39, step: 50, loss: 1.7397154569625854, samples_seen: 2448          \r"
     ]
    }
   ],
   "source": [
    "epochs = 500;  prev_loss = float(\"inf\")\n",
    "for epoch in range(history.len(), epochs):\n",
    "    start_time = time.time()\n",
    "    m = 0; epoch_loss = 0.0\n",
    "    n = 0; loss = tf.Variable(0.0, dtype=tf.float32); samples_seen = 0\n",
    "    selectivity = schedule(epoch)    # noralized_profit_pred_multiplier is scheduled here.\n",
    "\n",
    "    baseId_1 = None\n",
    "    train_batches = make_train_batches(train_ds)\n",
    "    for step, ((baseId, sequence, base_bb, mask), (base_label, seq_len_org)) in enumerate(train_batches):\n",
    "        if baseId_1 is None: baseId_1 = baseId[0]\n",
    "        # print('train', sequence.shape)\n",
    "        x = (sequence, base_bb, mask); y = base_label\n",
    "        batch_loss = train_step(x, y, selectivity)\n",
    "        n += 1; loss = loss * (n-1) / n + batch_loss / n\n",
    "        m += 1; epoch_loss = epoch_loss * (m-1)/m + batch_loss / m\n",
    "\n",
    "        samples_seen += sequence.shape[0]\n",
    "        if step % 50 == 0:\n",
    "            show_steps(epoch, step, loss, samples_seen)\n",
    "            n = 0; loss = 0.0\n",
    "\n",
    "    show_steps(epoch, step, loss, samples_seen)\n",
    "    val_loss = test_with_dataset(test_batches, selectivity)\n",
    "    profit_back_mean, nBettingsTotal = back_test_with_dataset(test_batches)\n",
    "    # back2 = back_test_with_dataset2(test_batches)\n",
    "    save_checkpoint(epoch_loss, val_loss, profit_back_mean, nBettingsTotal)     #------------------------------------------- comeback\n",
    "\n",
    "    eM365W = EPL.layers[0].layers[0].get_weights()[6]; eM365W = list(tf.reshape(eM365W, (-1,)).numpy())\n",
    "    # shift = tf.squeeze(EPL.layers[-1].get_weights()).numpy()\n",
    "    # dM365W =EPL.layers[0].layers[1].get_weights()[4]; dM365W = list(tf.reshape(dM365W, (-1,)).numpy())\n",
    "\n",
    "    print(\"epoch: {}, loss: {}, val_loss: {}, back_test: {}, nBettings: {}, baseId_1: {}, memory365: {:.4f},  time taken: {:.0f}s          \"\n",
    "          .format(epoch, float(epoch_loss), float(val_loss), float(profit_back_mean), nBettingsTotal, baseId_1, eM365W[0] * hyperparams.initial_m365, (time.time() - start_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
